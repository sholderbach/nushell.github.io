(window.webpackJsonp=window.webpackJsonp||[]).push([[908],{1424:function(s,a,t){"use strict";t.r(a);var e=t(35),n=Object(e.a)({},(function(){var s=this,a=s.$createElement,t=s._self._c||a;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("h1",{attrs:{id:"dataframes"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#dataframes"}},[s._v("#")]),s._v(" DataFrames")]),s._v(" "),t("div",{staticClass:"custom-block tip"},[t("p",{staticClass:"custom-block-title"},[s._v("TIP")]),s._v(" "),t("p",[s._v("DataFrame 相关命令从 0.33.1 版本开始支持")])]),s._v(" "),t("p",[s._v("正如我们到目前为止所看到的，Nushell 把数据处理作为其主要任务。"),t("code",[s._v("Lists")]),s._v(" 和 "),t("code",[s._v("Tables")]),s._v("的存在是为了帮助你循环处理值，以便执行多种操作或轻而易举地找到数据。然而，在某些操作中，基于行的数据布局并不是处理数据的最有效方式，特别是在处理极其庞大的文件时。对于大型数据集的"),t("code",[s._v("group-by")]),s._v("或"),t("code",[s._v("join")]),s._v("等操作，如果不使用适当的数据格式，会占用大量的内存，并可能耗费大量的计算时间。")]),s._v(" "),t("p",[s._v("出于这个原因，Nushell 引入了"),t("code",[s._v("DataFrame")]),s._v("结构。"),t("code",[s._v("DataFrame")]),s._v("以列格式存储数据，以 "),t("a",{attrs:{href:"https://arrow.apache.org/",target:"_blank",rel:"noopener noreferrer"}},[s._v("Apache Arrow"),t("OutboundLink")],1),s._v(" 规范为基础，并使用 "),t("a",{attrs:{href:"https://github.com/pola-rs/polars",target:"_blank",rel:"noopener noreferrer"}},[s._v("Polars"),t("OutboundLink")],1),s._v(" 作为执行极其 "),t("a",{attrs:{href:"https://h2oai.github.io/db-benchmark/",target:"_blank",rel:"noopener noreferrer"}},[s._v("快速列式操作"),t("OutboundLink")],1),s._v(" 的马达。")]),s._v(" "),t("p",[s._v("你现在可能想知道这个组合能有多快，以及它如何能使数据工作更容易、更可靠。出于这个原因，让我们在本页开始时介绍一下处理数据时的常见操作的性能测试情况。")]),s._v(" "),t("h2",{attrs:{id:"性能测试对比"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#性能测试对比"}},[s._v("#")]),s._v(" 性能测试对比")]),s._v(" "),t("p",[s._v("在这个小的性能测试练习中，我们将比较本地的 Nushell 原生命令、Nushell DataFrame 相关命令和"),t("a",{attrs:{href:"https://pandas.pydata.org/",target:"_blank",rel:"noopener noreferrer"}},[s._v("Python Pandas"),t("OutboundLink")],1),s._v("命令。暂时不要太在意"),t("code",[s._v("dataframe")]),s._v("命令，它们将在本页后面的章节中解释。")]),s._v(" "),t("blockquote",[t("p",[s._v("系统细节：本节介绍的性能测试是用一台配备 Intel(R) Core(TM) i7-10710U\n（CPU @1.10GHz 1.61GHz）和 16 GB 内存的机器运行的。")]),s._v(" "),t("p",[s._v("所有的例子都在 Nushell 0.33.1 版本上运行。")])]),s._v(" "),t("h3",{attrs:{id:"文件信息"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#文件信息"}},[s._v("#")]),s._v(" 文件信息")]),s._v(" "),t("p",[s._v("我们将用于性能测试的文件是 "),t("a",{attrs:{href:"https://www.stats.govt.nz/assets/Uploads/New-Zealand-business-demography-statistics/New-Zealand-business-demography-statistics-At-February-2020/Download-data/Geographic-units-by-industry-and-statistical-area-2000-2020-descending-order-CSV.zip",target:"_blank",rel:"noopener noreferrer"}},[s._v("新西兰商业人口统计"),t("OutboundLink")],1),s._v(" 数据集。\n如果你想尝试这些测试，请下载该文件。")]),s._v(" "),t("p",[s._v("该数据集有 5 列，5,429,252 行。我们可以通过使用"),t("code",[s._v("dfr list")]),s._v("命令来检查：")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("let")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("df")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("dfr "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("open")]),s._v(" ."),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v("Data7602DescendingYearOrder.csv"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" dfr list\n\n───┬──────┬─────────┬─────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# │ name │  rows   │ columns")]),s._v("\n───┼──────┼─────────┼─────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$df")]),s._v("  │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5429252")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),s._v("\n───┴──────┴─────────┴─────────\n")])])]),t("p",[s._v("我们可以用"),t("code",[s._v("dfr first")]),s._v("看一下文件的第一行：")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$df")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" dfr first\n\n───┬──────────┬─────────┬──────┬───────────┬──────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# │ anzsic06 │  Area   │ year │ geo_count │ ec_count")]),s._v("\n───┼──────────┼─────────┼──────┼───────────┼──────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │ A        │ A100100 │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2000")]),s._v(" │        "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("96")]),s._v(" │      "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("130")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" │ A        │ A100200 │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2000")]),s._v(" │       "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("198")]),s._v(" │      "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("110")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" │ A        │ A100300 │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2000")]),s._v(" │        "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("42")]),s._v(" │       "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("25")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v(" │ A        │ A100400 │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2000")]),s._v(" │        "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("66")]),s._v(" │       "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("40")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v(" │ A        │ A100500 │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2000")]),s._v(" │        "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("63")]),s._v(" │       "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("40")]),s._v("\n───┴──────────┴─────────┴──────┴───────────┴──────────\n")])])]),t("p",[s._v("...最后，我们可以了解一下推断出的数据类型：")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$df")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" dfr dtypes\n\n───┬───────────┬───────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# │  column   │ dtype")]),s._v("\n───┼───────────┼───────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │ anzsic06  │ str\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" │ Area      │ str\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" │ year      │ i64\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v(" │ geo_count │ i64\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v(" │ ec_count  │ i64\n───┴───────────┴───────\n")])])]),t("h3",{attrs:{id:"加载文件"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#加载文件"}},[s._v("#")]),s._v(" 加载文件")]),s._v(" "),t("p",[s._v("让我们先来比较一下各种方法的加载时间。首先，我们将使用 Nushell 的"),t("RouterLink",{attrs:{to:"/book/commands/open.html"}},[t("code",[s._v("open")])]),s._v("命令加载数据：")],1),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" benchmark "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("open ."),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v("Data7602DescendingYearOrder.csv"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n───┬─────────────────────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# │        real time")]),s._v("\n───┼─────────────────────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │ 30sec 479ms 614us 400ns\n───┴─────────────────────────\n")])])]),t("p",[s._v("使用原生的 Nushell 功能加载文件需要 30 秒。对于加载 500 万条记录来说，这还算不错！但我们可以做得更好一些。")]),s._v(" "),t("p",[s._v("现在让我们使用 Pandas。我们将使用以下脚本来加载文件：")]),s._v(" "),t("div",{staticClass:"language-python extra-class"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" pandas "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" pd\n\ndf "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" pd"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("read_csv"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Data7602DescendingYearOrder.csv"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])])]),t("p",[s._v("而它的性能测试结果是：")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" benchmark "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("python load.py"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n───┬───────────────────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# │       real time")]),s._v("\n───┼───────────────────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │ 2sec 91ms 872us 900ns\n───┴───────────────────────\n")])])]),t("p",[s._v("这是一个很大的进步，从 30 秒到 2 秒。干得好，Pandas!")]),s._v(" "),t("p",[s._v("也许我们加载数据可以再快一点，这一次我们将使用 Nushell 的"),t("code",[s._v("dfr open")]),s._v("命令：")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" benchmark "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("dfr "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("open")]),s._v(" ."),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v("Data7602DescendingYearOrder.csv"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n───┬───────────────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# │     real time")]),s._v("\n───┼───────────────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │ 601ms 700us 700ns\n───┴───────────────────\n")])])]),t("p",[s._v("这一次，我们花了 0.6 秒。一点也不差。")]),s._v(" "),t("h3",{attrs:{id:"group-by比较"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#group-by比较"}},[s._v("#")]),s._v(" "),t("code",[s._v("Group-by")]),s._v("比较")]),s._v(" "),t("p",[s._v("这次让我们做一个稍微复杂的操作。我们将按年份对数据进行分组，并根据"),t("code",[s._v("geo_count")]),s._v("列对分组求和。")]),s._v(" "),t("p",[s._v("同样，我们要从 Nushell 的原生命令开始：")]),s._v(" "),t("div",{staticClass:"custom-block tip"},[t("p",{staticClass:"custom-block-title"},[s._v("TIP")]),s._v(" "),t("p",[s._v("如果你想运行这个例子，请注意接下来的命令将使用大量的内存，在该命令执行期间可能会影响你的系统性能。")])]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" benchmark "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("open")]),s._v(" ."),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v("Data7602DescendingYearOrder.csv\n\t"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" group-by year\n\t"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" pivot header rows\n\t"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" upsert rows "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v(" get rows "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" math "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("sum")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\t"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" flatten\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n───┬────────────────────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# │       real time")]),s._v("\n───┼────────────────────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │ 6min 30sec 622ms 312us\n───┴────────────────────────\n")])])]),t("p",[s._v("所以，执行这个聚合操作需要 6 分钟。")]),s._v(" "),t("p",[s._v("让我们试试在"),t("code",[s._v("pandas")]),s._v("中进行同样的操作：")]),s._v(" "),t("div",{staticClass:"language-python extra-class"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" pandas "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" pd\n\ndf "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" pd"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("read_csv"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"Data7602DescendingYearOrder.csv"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nres "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" df"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("groupby"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"year"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"geo_count"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("sum")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("res"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])])]),t("p",[s._v("而性能测试的结果是：")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" benchmark "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("python ."),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("\\")]),s._v("load.py"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n───┬────────────────────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# │       real time")]),s._v("\n───┼────────────────────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │ 1sec 966ms 954us 800ns\n───┴────────────────────────\n")])])]),t("p",[s._v("一点也不差！同样，Pandas 设法在很短的时间内完成了它。")]),s._v(" "),t("p",[s._v("为了进行比较，让我们试试 Nushell DataFrames。我们要把所有的操作放在一个"),t("code",[s._v("nu")]),s._v("文件中，以确保我们做的是类似的操作：")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("let")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("df")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("dfr "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("open")]),s._v(" Data7602DescendingYearOrder.csv"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("let")]),s._v(" res "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$df")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" dfr group-by year "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" dfr aggregate "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("sum")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" dfr "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" geo_count"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$res")]),s._v("\n")])])]),t("p",[s._v("当使用 DataFrames 时的性能测试结果是：")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" benchmark "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("source load.nu"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n\n───┬───────────────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# │     real time")]),s._v("\n───┼───────────────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │ 557ms 658us 500ns\n───┴───────────────────\n")])])]),t("p",[s._v("幸运的是，Nushell DataFrame 设法将时间再次减半。这不是很好吗？")]),s._v(" "),t("p",[s._v("正如你所看到的，Nushell 的"),t("code",[s._v("DataFrame")]),s._v("命令和现在最常见的做数据分析的工具一样快。这个发行版中的命令有可能成为你做数据分析的首选工具。通过组合复杂的 Nushell 管道，你可以以一种可靠的方式从数据中提取信息。")]),s._v(" "),t("h2",{attrs:{id:"使用-dataframes"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#使用-dataframes"}},[s._v("#")]),s._v(" 使用 DataFrames")]),s._v(" "),t("p",[s._v("在看到了可以用"),t("code",[s._v("DataFrame")]),s._v("命令完成的事情之后，现在是时候开始测试它们了。首先，让我们创建一个样本 CSV 文件，该文件将成为我们的样本 DataFrame，并与示例一起使用。在你喜欢的编辑器中粘贴下面几行来创建样本 csv 文件：")]),s._v(" "),t("div",{staticClass:"language-csv extra-class"},[t("pre",{pre:!0,attrs:{class:"language-csv"}},[t("code",[t("span",{pre:!0,attrs:{class:"token value"}},[s._v("int_1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("int_2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("float_1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("float_2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("first")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("second")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("third")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("word")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("11")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("0.1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("1.0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("a")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("b")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("c")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("first")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("12")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("0.2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("1.0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("a")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("b")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("c")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("second")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("3")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("13")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("0.3")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("2.0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("a")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("b")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("c")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("third")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("4")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("14")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("0.4")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("3.0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("b")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("a")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("c")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("second")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("15")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("0.5")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("4.0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("b")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("a")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("a")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("third")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("6")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("16")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("0.6")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("5.0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("b")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("a")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("a")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("second")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("7")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("17")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("0.7")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("6.0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("b")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("c")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("a")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("third")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("8")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("18")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("0.8")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("7.0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("c")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("c")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("b")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("eight")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("9")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("19")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("0.9")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("8.0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("c")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("c")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("b")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("ninth")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("10")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("0.0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("9.0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("c")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("c")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("b")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[s._v("ninth")]),s._v("\n")])])]),t("p",[s._v("保存该文件并随意命名，在这些例子中，该文件将被称为"),t("code",[s._v("test_small.csv")]),s._v("。")]),s._v(" "),t("p",[s._v("现在，要将该文件作为 DataFrame 进行读取，请使用"),t("code",[s._v("dfr open")]),s._v("命令，如下所示：")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("let")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("df")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("dfr "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("open")]),s._v(" test_small.csv"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])])]),t("p",[s._v("这应该会在内存中创建一个值"),t("code",[s._v("df")]),s._v("，用来存放我们刚刚创建的数据。")]),s._v(" "),t("div",{staticClass:"custom-block tip"},[t("p",{staticClass:"custom-block-title"},[s._v("TIP")]),s._v(" "),t("p",[t("code",[s._v("dfrs open")]),s._v("命令可以读取 "),t("strong",[s._v("csv")]),s._v(" 或 "),t("strong",[s._v("parquet")]),s._v(" 文件。")])]),s._v(" "),t("p",[s._v("要查看存储在内存中的所有 DataFrames，你可以使用：")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" dfr list\n\n───┬──────┬──────┬─────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# │ name │ rows │ columns")]),s._v("\n───┼──────┼──────┼─────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$df")]),s._v("  │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),s._v("   │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),s._v("\n───┴──────┴──────┴─────────\n")])])]),t("p",[s._v("正如你所看到的，该命令显示了所创建的 DataFrame 以及关于它们的基本信息。")]),s._v(" "),t("p",[s._v("如果你想看到加载的 DataFrame 的预览，你可以将 DataFrame 变量发送到流中：")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$df")]),s._v("\n\n───┬───────┬───────┬─────────┬─────────┬───────┬────────┬───────┬────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# │ int_1 │ int_2 │ float_1 │ float_2 │ first │ second │ third │  word")]),s._v("\n───┼───────┼───────┼─────────┼─────────┼───────┼────────┼───────┼────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("11")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.1000")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1.0000")]),s._v(" │ a     │ b      │ c     │ first\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("12")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.2000")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1.0000")]),s._v(" │ a     │ b      │ c     │ second\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("13")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.3000")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2.0000")]),s._v(" │ a     │ b      │ c     │ third\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("14")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.4000")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3.0000")]),s._v(" │ b     │ a      │ c     │ second\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("15")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.5000")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4.0000")]),s._v(" │ b     │ a      │ a     │ third\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("16")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.6000")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5.0000")]),s._v(" │ b     │ a      │ a     │ second\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("7")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("17")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.7000")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6.0000")]),s._v(" │ b     │ c      │ a     │ third\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("7")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("18")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.8000")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("7.0000")]),s._v(" │ c     │ c      │ b     │ eight\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("9")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("19")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.9000")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("8.0000")]),s._v(" │ c     │ c      │ b     │ ninth\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("9")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.0000")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("9.0000")]),s._v(" │ c     │ c      │ b     │ ninth\n───┴───────┴───────┴─────────┴─────────┴───────┴────────┴───────┴────────\n")])])]),t("p",[s._v("有了内存中的 DataFrame，我们就可以开始对 "),t("code",[s._v("DataFrame")]),s._v(" 进行列操作。")]),s._v(" "),t("div",{staticClass:"custom-block tip"},[t("p",{staticClass:"custom-block-title"},[s._v("TIP")]),s._v(" "),t("p",[s._v("如果你想看到所有可用的 DataFrame 命令，你可以使用"),t("code",[s._v("help dfr")]),s._v("。")])]),s._v(" "),t("h2",{attrs:{id:"基本聚合"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#基本聚合"}},[s._v("#")]),s._v(" 基本聚合")]),s._v(" "),t("p",[s._v("让我们从 DataFrame 的基本聚合开始，通过使用"),t("code",[s._v("aggregate")]),s._v("命令对"),t("code",[s._v("df")]),s._v("中存在的所有列进行求和：")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$df")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" dfr aggregate "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("sum")]),s._v("\n\n───┬───────┬───────┬─────────┬─────────┬───────┬────────┬───────┬──────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# │ int_1 │ int_2 │ float_1 │ float_2 │ first │ second │ third │ word")]),s._v("\n───┼───────┼───────┼─────────┼─────────┼───────┼────────┼───────┼──────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("40")]),s._v(" │   "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("145")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4.5000")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("46.0000")]),s._v(" │       │        │       │\n───┴───────┴───────┴─────────┴─────────┴───────┴────────┴───────┴──────\n")])])]),t("p",[s._v("正如你所看到的，聚合函数("),t("code",[s._v("aggregate")]),s._v(")为那些有意义的列计算出了总和。如果你想过滤掉文本列，你可以使用"),t("code",[s._v("select")]),s._v("命令来选择你想要的列。")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$df")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" dfr aggregate "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("sum")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" dfr "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" int_1 int_2 float_1 float_2\n\n───┬───────┬───────┬─────────┬─────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# │ int_1 │ int_2 │ float_1 │ float_2")]),s._v("\n───┼───────┼───────┼─────────┼─────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("40")]),s._v(" │   "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("145")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4.5000")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("46.0000")]),s._v("\n───┴───────┴───────┴─────────┴─────────\n")])])]),t("p",[s._v("你甚至可以像存储任何其他 Nushell 变量一样存储这个聚合的结果：")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("let")]),s._v(" res "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$df")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" dfr aggregate "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("sum")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" dfr "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" int_1 int_2 float_1 float_2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])])]),t("p",[s._v("现在我们有两个 DataFrame 存储在内存中：")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" dfr list\n\n───┬──────┬──────┬─────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# │ name │ rows │ columns")]),s._v("\n───┼──────┼──────┼─────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$df")]),s._v("  │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),s._v("   │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$res")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("    │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v("\n───┴──────┴──────┴─────────\n")])])]),t("p",[s._v("很整洁，不是吗？")]),s._v(" "),t("p",[s._v("你可以在 DataFrame 上进行若干聚合，以便从中提取基本信息，也可以对你的全新 DataFrame 进行基本数据分析。")]),s._v(" "),t("h2",{attrs:{id:"连接-dataframe"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#连接-dataframe"}},[s._v("#")]),s._v(" 连接 DataFrame")]),s._v(" "),t("p",[s._v("也可以用一个列作为参考来连接("),t("code",[s._v("join")]),s._v(")两个 DataFrame。我们将把我们的迷你 DataFrame 与另一个迷你 DataFrame 连接起来。在另一个文件中复制这些行，并创建相应的 DataFrame（在以下例子中，我们将称之为"),t("code",[s._v("test_small_a.csv")]),s._v("）。")]),s._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[s._v("int_1a,int_2,float_1,float_2,first\n9,14,0.4,3.0,a\n8,13,0.3,2.0,a\n7,12,0.2,1.0,a\n6,11,0.1,0.0,b\n")])])]),t("p",[s._v("我们使用"),t("code",[s._v("dfr open")]),s._v("命令来创建新的变量：")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("let")]),s._v(" df_a "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("dfr "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("open")]),s._v(" test_small_a.csv"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])])]),t("p",[s._v("现在，当第二个 DataFrame 加载到内存中时，我们可以使用左边 DataFrame 的"),t("code",[s._v("int_1")]),s._v("列和右边 DataFrame 的"),t("code",[s._v("int_1a")]),s._v("列来连接它们。")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$df")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" dfr "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("join")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$df_a")]),s._v(" -l "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("int_1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" -r "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("int_1a"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n\n───┬───────┬───────┬─────────┬─────────┬───────┬────────┬───────┬─────────┬─────────────┬───────────────┬───────────────┬─────────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# │ int_1 │ int_2 │ float_1 │ float_2 │ first │ second │ third │  word   │ int_2_right │ float_1_right │ float_2_right │ first_right")]),s._v("\n───┼───────┼───────┼─────────┼─────────┼───────┼────────┼───────┼─────────┼─────────────┼───────────────┼───────────────┼─────────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("16")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.6000")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5.0000")]),s._v(" │ b     │ a      │ a     │ second  │          "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("11")]),s._v(" │        "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.1000")]),s._v(" │        "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.0000")]),s._v(" │ b\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("7")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("17")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.7000")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6.0000")]),s._v(" │ b     │ c      │ a     │ third   │          "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("12")]),s._v(" │        "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.2000")]),s._v(" │        "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1.0000")]),s._v(" │ a\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("18")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.8000")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("7.0000")]),s._v(" │ c     │ c      │ b     │ eight   │          "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("13")]),s._v(" │        "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.3000")]),s._v(" │        "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2.0000")]),s._v(" │ a\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("9")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("19")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.9000")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("8.0000")]),s._v(" │ c     │ c      │ b     │ ninth   │          "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("14")]),s._v(" │        "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.4000")]),s._v(" │        "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3.0000")]),s._v(" │ a\n───┴───────┴───────┴─────────┴─────────┴───────┴────────┴───────┴─────────┴─────────────┴───────────────┴───────────────┴─────────────\n")])])]),t("div",{staticClass:"custom-block tip"},[t("p",{staticClass:"custom-block-title"},[s._v("TIP")]),s._v(" "),t("p",[s._v("在"),t("code",[s._v("Nu")]),s._v("中，当一个命令有多个参数，并期望得到多个值时，我们用方括号"),t("code",[s._v("[]")]),s._v("来包裹这些值。在"),t("code",[s._v("dfr join")]),s._v("的情况下，我们可以对多个列进行连接，只要它们具有相同的类型，例如我们可以这样做："),t("code",[s._v("$df | dfr join $df_a -l [int_1 int_2] -r [int_1a int_2]")]),s._v("。")])]),s._v(" "),t("p",[s._v("默认情况下，连接命令做的是内连接，也就是说，它将保留两个 DataFrame 都有相同值的记录。你可以选择一个左联接来保留左边 DataFrame 中缺失的行。你也可以保存这个结果，以便在以后的操作中使用它。")]),s._v(" "),t("h2",{attrs:{id:"dataframe-分组"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#dataframe-分组"}},[s._v("#")]),s._v(" DataFrame 分组")]),s._v(" "),t("p",[s._v("可以用 DataFrame 进行的最强大的操作之一是"),t("code",[s._v("group-by")]),s._v("。这个命令将允许你根据一个分组条件进行聚合操作。在 Nushell 中，"),t("code",[s._v("GroupBy")]),s._v("是一种可以被存储和重复使用的对象，可以被用于多个聚合。这是很方便的，因为在进行分组时，创建分组对是最昂贵的运算，如果你打算用同一个分组条件进行多个操作，就没有必要重复该运算。")]),s._v(" "),t("p",[s._v("要创建一个"),t("code",[s._v("GroupBy")]),s._v("对象，你只需要使用"),t("code",[s._v("group-by")]),s._v("命令：")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("let")]),s._v(" group "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$df")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" dfr group-by first"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$group")]),s._v("\n\n───┬──────────┬───────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# │ property │ value")]),s._v("\n───┼──────────┼───────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │ group by │ first\n───┴──────────┴───────\n")])])]),t("p",[s._v("当打印 "),t("code",[s._v("GroupBy")]),s._v(" 对象时，我们可以看到被用作条件的列来对 DataFrame 进行分组。使用"),t("code",[s._v("GroupBy")]),s._v("，我们可以使用多种操作对 DataFrame 进行聚合。")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$group")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" dfr aggregate "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("sum")]),s._v("\n\n───┬───────┬───────────┬───────────┬─────────────┬─────────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# │ first │ int_1     │ int_2     │ float_1     │ float_2")]),s._v("\n───┼───────┼───────────┼───────────┼─────────────┼─────────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │ a     │         "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6")]),s._v(" │        "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("36")]),s._v(" │      "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.6000")]),s._v(" │      "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4.0000")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" │ b     │        "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("17")]),s._v(" │        "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("62")]),s._v(" │      "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2.2000")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("18.0000")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" │ c     │        "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("17")]),s._v(" │        "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("47")]),s._v(" │      "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1.7000")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("24.0000")]),s._v("\n───┴───────┴───────────┴───────────┴─────────────┴─────────────\n")])])]),t("p",[s._v("使用同样的 "),t("code",[s._v("GroupBy")]),s._v("，你可以对整个 DataFrame 进行另一个操作，比如本例中的"),t("code",[s._v("min")]),s._v("：")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$group")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" aggregate min\n\n───┬───────┬───────────┬───────────┬─────────────┬─────────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# │ first │ int_1     │ int_2     │ float_1     │ float_2")]),s._v("\n───┼───────┼───────────┼───────────┼─────────────┼─────────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │ a     │         "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" │        "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("11")]),s._v(" │      "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.1000")]),s._v(" │      "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1.0000")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" │ b     │         "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │        "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("14")]),s._v(" │      "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.4000")]),s._v(" │      "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3.0000")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" │ c     │         "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │        "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),s._v(" │      "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.0000")]),s._v(" │      "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("7.0000")]),s._v("\n───┴───────┴───────────┴───────────┴─────────────┴─────────────\n")])])]),t("p",[s._v("创建的"),t("code",[s._v("GroupBy")]),s._v("对象非常方便，它甚至可以被用作表格透视的基础。作为一个例子，让我们使用名为"),t("code",[s._v("second")]),s._v("的列作为透视列，而"),t("code",[s._v("float_1")]),s._v("列作为值列：")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$group")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" dfr pivot second float_1 "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("sum")]),s._v("\n\n───┬───────┬────────┬────────┬────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# │ first │   b    │   a    │   c")]),s._v("\n───┼───────┼────────┼────────┼────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │ a     │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.6000")]),s._v(" │        │\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" │ c     │        │        │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1.7000")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" │ b     │        │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1.5000")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.7000")]),s._v("\n───┴───────┴────────┴────────┴────────\n")])])]),t("div",{staticClass:"custom-block tip"},[t("p",{staticClass:"custom-block-title"},[s._v("TIP")]),s._v(" "),t("p",[s._v("透视操作是一种基于两列数据进行聚合的方法。在前面的例子中，透视命令的结果产生了一个表格，代表了列"),t("code",[s._v("float_1")]),s._v("中所有数值的总和，这些数值在列"),t("code",[s._v("first")]),s._v("（现在是行）和"),t("code",[s._v("second")]),s._v("（现在是列）中共享。因此，显示在第"),t("code",[s._v("b")]),s._v("行和第"),t("code",[s._v("a")]),s._v("列的值"),t("code",[s._v("1.5")]),s._v("是所有浮点的总和，其中第"),t("code",[s._v("first")]),s._v("列是"),t("code",[s._v("b")]),s._v("，第"),t("code",[s._v("second")]),s._v("列是"),t("code",[s._v("a")]),s._v("。")])]),s._v(" "),t("p",[s._v("正如你所看到的，"),t("code",[s._v("GroupBy")]),s._v("对象是一个非常强大的变量，在你操作数据集时，它值得被保留在内存中。")]),s._v(" "),t("h2",{attrs:{id:"创建-dataframes"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#创建-dataframes"}},[s._v("#")]),s._v(" 创建 DataFrames")]),s._v(" "),t("p",[s._v("也可以从基本的 Nushell 基础类型，如整数、小数或字符串，来构建 DataFrames。让我们使用"),t("code",[s._v("to-df")]),s._v("命令来创建一个小的 DataFrame：")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("let")]),s._v(" a "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("a b"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" dfr to-df"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$a")]),s._v("\n\n───┬───┬───\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# │ b │ a")]),s._v("\n───┼───┼───\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),s._v("\n───┴───┴───\n")])])]),t("div",{staticClass:"custom-block tip"},[t("p",{staticClass:"custom-block-title"},[s._v("TIP")]),s._v(" "),t("p",[s._v("目前，并不是所有的 Nushell 基本类型都可以转换为 DataFrame。随着 DataFrame 功能的成熟，这一点将在未来发生变化。")])]),s._v(" "),t("p",[s._v("我们可以在一个 DataFrame 中添加列，以创建一个新的变量。作为一个例子，让我们在迷你 DataFrame "),t("code",[s._v("$a")]),s._v(" 上添加两列：")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("let")]),s._v(" a2 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$a")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" dfr with-column "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$a")]),s._v(".a --name a2 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" dfr with-column "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$a")]),s._v(".a --name a3"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n───┬───┬───┬────┬────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# │ b │ a │ a2 │ a3")]),s._v("\n───┼───┼───┼────┼────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),s._v("\n───┴───┴───┴────┴────\n")])])]),t("p",[s._v("Nushell 强大的管道语法允许我们通过从其他 DataFrame 中获取数据并将其附加到这些 DataFrame 中来创建新的 DataFrame。现在，如果你列出你的 DataFrame，你会看到总共有四个：")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" dfr list\n\n───┬───────┬──────┬─────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# │  name │ rows │ columns")]),s._v("\n───┼───────┼──────┼─────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$a")]),s._v("    │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v("    │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$a2")]),s._v("   │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v("    │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$df_a")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v("    │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$df")]),s._v("   │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),s._v("   │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),s._v("\n───┴───────┴──────┴─────────\n")])])]),t("p",[s._v("值得一提的是，在使用 DataFrame 时，内存是如何被优化的呢？这要感谢 "),t("strong",[s._v("Apache Arrow")]),s._v(" 和 "),t("strong",[s._v("Polars")]),s._v("。在一个非常简单的表示中，DataFrame 中的每一列都是一个 Arrow 数组，它使用了几种内存规格，以塞满尽可能多的数据（查看 "),t("a",{attrs:{href:"https://arrow.apache.org/docs/format/Columnar.html",target:"_blank",rel:"noopener noreferrer"}},[s._v("Arrow 列格式"),t("OutboundLink")],1),s._v(" ）；另一个优化技巧是，只要有可能，DataFrame 中的列就会在多个 DataFrame 之间共享，避免了相同数据的内存重复占用。这意味着 DataFrame "),t("code",[s._v("$a")]),s._v("和"),t("code",[s._v("$a2")]),s._v("共享我们用"),t("code",[s._v("to-df")]),s._v("命令创建的两个列。由于这个原因，不能改变 DataFrame 中某一列的值。然而，你可以根据其他列或 DataFrame 的数据创建新的列。")]),s._v(" "),t("h2",{attrs:{id:"使用系列"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#使用系列"}},[s._v("#")]),s._v(" 使用系列")]),s._v(" "),t("p",[s._v("系列("),t("code",[s._v("Series")]),s._v(") 是 "),t("code",[s._v("DataFrame")]),s._v(" 的基本组成部分。每个系列代表一个具有相同数据类型的列，我们可以创建多个不同类型的系列，如浮点、整型或字符串。")]),s._v(" "),t("p",[s._v("让我们通过使用"),t("code",[s._v("to-df")]),s._v("命令创建一个系列，来开始我们对系列的探索：")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("let")]),s._v(" new "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("9")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" dfr to-df"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$new")]),s._v("\n\n───┬───\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# │ 0")]),s._v("\n───┼───\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("9")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v("\n───┴───\n")])])]),t("p",[s._v("我们从一个整数列表创建了一个新的系列（我们也可以用浮点数或字符串做同样的事情）。")]),s._v(" "),t("p",[s._v("系列已经定义了自己的基本操作，它们可以用来创建其他系列。让我们通过对先前创建的列进行一些运算来创建一个新的系列：")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("let")]),s._v(" new_2 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$new")]),s._v(" * "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v(" + "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$new_2")]),s._v("\n\n───┬────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# │ 0")]),s._v("\n───┼────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("37")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("34")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("22")]),s._v("\n───┴────\n")])])]),t("p",[s._v("现在我们有一个新的系列，它是通过对前一个变量进行基本操作而构建的。")]),s._v(" "),t("div",{staticClass:"custom-block tip"},[t("p",{staticClass:"custom-block-title"},[s._v("TIP")]),s._v(" "),t("p",[s._v("如果你想看看你在内存中存储了多少变量，你可以使用"),t("code",[s._v("$nu.scope.vars")]),s._v("。")])]),s._v(" "),t("p",[s._v("让我们重新命名我们之前的系列为 "),t("code",[s._v("memorable")])]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("let")]),s._v(" new_2 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$new_2")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" dfr "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("rename")]),s._v(" memorable"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$new_2")]),s._v("\n\n───┬───────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# │ memorable")]),s._v("\n───┼───────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │        "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("37")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" │        "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("34")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" │        "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("22")]),s._v("\n───┴───────────\n")])])]),t("p",[s._v("只要两个系列的数据类型相同，我们也可以对它们进行基本操作：")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$new")]),s._v(" - "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$new_2")]),s._v("\n\n───┬──────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# │ sub_0_0")]),s._v("\n───┼──────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │     -28\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" │     -26\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" │     -18\n───┴──────────\n")])])]),t("p",[s._v("而且我们可以将它们添加到先前定义的 DataFrames 中：")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("let")]),s._v(" new_df "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$a")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" dfr with-column "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$new")]),s._v(" --name new_col"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$new_df")]),s._v("\n\n───┬───┬───┬─────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# │ b │ a │ new_col")]),s._v("\n───┼───┼───┼─────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" │       "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("9")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v(" │       "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),s._v(" │       "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v("\n───┴───┴───┴─────────\n")])])]),t("p",[s._v("存储在 DataFrame 中的系列也可以直接使用，例如，我们可以将列"),t("code",[s._v("a")]),s._v("和"),t("code",[s._v("b")]),s._v("相乘来创建一个新系列：")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$new_df")]),s._v(".a * "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$new_df")]),s._v(".b\n\n───┬─────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# │ mul_a_b")]),s._v("\n───┼─────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │       "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" │      "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("12")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" │      "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("30")]),s._v("\n───┴─────────\n")])])]),t("p",[s._v("我们可以开始使用管道，以创建新的列和 DataFrames：")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("let")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$new_df")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$new_df")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" dfr with-column "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$new_df")]),s._v(".a * "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$new_df")]),s._v(".b / "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$new_df")]),s._v(".new_col"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" --name my_sum"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("let")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$new_df")]),s._v("\n\n───┬───┬───┬─────────┬────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# │ b │ a │ new_col │ my_sum")]),s._v("\n───┼───┼───┼─────────┼────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" │       "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("9")]),s._v(" │      "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v(" │       "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),s._v(" │      "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),s._v(" │       "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v(" │      "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("7")]),s._v("\n───┴───┴───┴─────────┴────────\n")])])]),t("p",[s._v("Nushell 的管道系统可以帮助你创建非常有趣的工作流程。")]),s._v(" "),t("h2",{attrs:{id:"系列和掩码"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#系列和掩码"}},[s._v("#")]),s._v(" 系列和掩码")]),s._v(" "),t("p",[s._v("在使用 DataFrames 时，系列还有另一个关键用途，那就是我们可以用它们来建立布尔掩码（Mask）。让我们先用等于运算符创建一个简单的掩码：")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("let")]),s._v(" mask "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$mask")]),s._v("\n\n───┬─────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# │ new_col")]),s._v("\n───┼─────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("false")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("true")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("false")]),s._v("\n───┴─────────\n")])])]),t("p",[s._v("有了这个掩码，我们现在可以过滤一个 DataFrame，像这样：")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$new_df")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" dfr filter-with "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$mask")]),s._v("\n\n───┬───┬───┬─────────┬────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# │ a │ b │ new_col │ my_sum")]),s._v("\n───┼───┼───┼─────────┼────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v(" │       "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),s._v(" │      "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("\n───┴───┴───┴─────────┴────────\n")])])]),t("p",[s._v("现在我们有一个新的 DataFrame，其中只有掩码为真的值。")]),s._v(" "),t("p",[s._v("掩码也可以从 Nushell 列表中创建，比如：")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("let")]),s._v(" mask1 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("true "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("true")]),s._v(" false"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" dfr to-df mask"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$new_df")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" dfr filter-with "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$mask1")]),s._v("\n\n───┬───┬───┬─────────┬────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# │ a │ b │ new_col │ my_sum")]),s._v("\n───┼───┼───┼─────────┼────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" │       "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("9")]),s._v(" │      "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v(" │       "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),s._v(" │      "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("\n───┴───┴───┴─────────┴────────\n")])])]),t("p",[s._v("为了创建复杂的掩码，我们可以使用"),t("code",[s._v("AND")]),s._v("：")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$mask")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("&&")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$mask1")]),s._v("\n\n───┬──────────────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# │ and_new_col_mask")]),s._v("\n───┼──────────────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("false")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("true")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("false")]),s._v("\n───┴──────────────────\n")])])]),t("p",[s._v("或者 "),t("code",[s._v("OR")]),s._v(" 操作：")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$mask")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("||")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$mask1")]),s._v("\n\n───┬─────────────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# │ or_new_col_mask")]),s._v("\n───┼─────────────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("true")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("true")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("false")]),s._v("\n───┴─────────────────\n")])])]),t("p",[s._v("我们也可以通过检查某些值是否存在于其他系列来创建一个掩码。使用我们创建的第一个 DataFrame，我们可以这样做：")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("let")]),s._v(" mask3 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$df")]),s._v(".first "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" dfr is-in "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("b c"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" dfr to-df"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("))")]),s._v("\n\n───┬──────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# │ first")]),s._v("\n───┼───────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("false")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("false")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("false")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("true")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("true")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("true")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("true")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("7")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("true")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("true")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("9")]),s._v(" │ "),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("true")]),s._v("\n───┴───────\n")])])]),t("p",[s._v("而这个新的掩码可以用来过滤 DataFrame")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$df")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" dfr filter-with "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$mask3")]),s._v("\n\n───┬───────┬───────┬─────────┬─────────┬───────┬────────┬───────┬─────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# │ int_1 │ int_2 │ float_1 │ float_2 │ first │ second │ third │  word")]),s._v("\n───┼───────┼───────┼─────────┼─────────┼───────┼────────┼───────┼─────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("14")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.4000")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3.0000")]),s._v(" │ b     │ a      │ c     │ second\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("15")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.5000")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4.0000")]),s._v(" │ b     │ a      │ a     │ third\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("16")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.6000")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5.0000")]),s._v(" │ b     │ a      │ a     │ second\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("7")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("17")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.7000")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6.0000")]),s._v(" │ b     │ c      │ a     │ third\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("18")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.8000")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("7.0000")]),s._v(" │ c     │ c      │ b     │ eight\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("9")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("19")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.9000")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("8.0000")]),s._v(" │ c     │ c      │ b     │ ninth\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.0000")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("9.0000")]),s._v(" │ c     │ c      │ b     │ ninth\n───┴───────┴───────┴─────────┴─────────┴───────┴────────┴───────┴─────────\n")])])]),t("p",[s._v("另一个可以用掩码进行的操作是设置或替换一个系列的值。例如，我们可以改变列"),t("code",[s._v("first")]),s._v("中的值，如果该值包含"),t("code",[s._v("a")]),s._v("：")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$df")]),s._v(".first "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" dfr "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("set")]),s._v(" new --mask "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$df")]),s._v(".first "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=~")]),s._v(" a"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n───┬────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# │ string")]),s._v("\n───┼────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │ new\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" │ new\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" │ new\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v(" │ b\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v(" │ b\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),s._v(" │ b\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6")]),s._v(" │ b\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("7")]),s._v(" │ c\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),s._v(" │ c\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("9")]),s._v(" │ c\n───┴────────\n")])])]),t("h2",{attrs:{id:"系列作为索引"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#系列作为索引"}},[s._v("#")]),s._v(" 系列作为索引")]),s._v(" "),t("p",[s._v("系列也可以作为过滤 DataFrame 的一种方式，将它们作为索引列表使用。例如，假设我们想从原始 DataFrame 中获取第1、4和6行。针对这一点，我们可以使用以下命令来提取这些信息：")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("let")]),s._v(" indices "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" dfr to-df"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$df")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" dfr take "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$indices")]),s._v("\n\n───┬───────┬───────┬─────────┬─────────┬───────┬────────┬───────┬────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# │ int_1 │ int_2 │ float_1 │ float_2 │ first │ second │ third │  word")]),s._v("\n───┼───────┼───────┼─────────┼─────────┼───────┼────────┼───────┼────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("12")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.2000")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1.0000")]),s._v(" │ a     │ b      │ c     │ second\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("15")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.5000")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4.0000")]),s._v(" │ b     │ a      │ a     │ third\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("7")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("17")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.7000")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6.0000")]),s._v(" │ b     │ c      │ a     │ third\n───┴───────┴───────┴─────────┴─────────┴───────┴────────┴───────┴────────\n")])])]),t("p",[s._v("命令"),t("code",[s._v("take")]),s._v("非常方便，特别是当我们把它与其他命令混合使用时。\n比方说，我们想提取列"),t("code",[s._v("first")]),s._v("的唯一元素的所有行。为了做到这一点，我们可以使用"),t("code",[s._v("dfr arg-unique")]),s._v("命令，如下例所示：")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("let")]),s._v(" indices "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$df")]),s._v(".first "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" dfr arg-unique"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$df")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" dfr take "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$indices")]),s._v("\n\n───┬───────┬───────┬─────────┬─────────┬───────┬────────┬───────┬────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# │ int_1 │ int_2 │ float_1 │ float_2 │ first │ second │ third │  word")]),s._v("\n───┼───────┼───────┼─────────┼─────────┼───────┼────────┼───────┼────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("11")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.1000")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1.0000")]),s._v(" │ a     │ b      │ c     │ first\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("14")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.4000")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3.0000")]),s._v(" │ b     │ a      │ c     │ second\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("18")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.8000")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("7.0000")]),s._v(" │ c     │ c      │ b     │ eight\n───┴───────┴───────┴─────────┴─────────┴───────┴────────┴───────┴────────\n")])])]),t("p",[s._v("或者，如果我们想使用一个特定的列来创建一个新的有序 DataFrame，该怎么办？我们可以使用"),t("code",[s._v("dfr arg-sort")]),s._v("来完成这个任务。在下一个例子中，我们可以通过"),t("code",[s._v("word")]),s._v("列对 DataFrame 进行排序：")]),s._v(" "),t("div",{staticClass:"custom-block tip"},[t("p",{staticClass:"custom-block-title"},[s._v("TIP")]),s._v(" "),t("p",[s._v("同样的结果也可以用"),t("code",[s._v("sort")]),s._v("命令来完成。")])]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("let")]),s._v(" indices "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$df")]),s._v(".word "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" dfr arg-sort"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$df")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" dfr take "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$indices")]),s._v("\n\n───┬───────┬───────┬─────────┬─────────┬───────┬────────┬───────┬────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# │ int_1 │ int_2 │ float_1 │ float_2 │ first │ second │ third │  word")]),s._v("\n───┼───────┼───────┼─────────┼─────────┼───────┼────────┼───────┼────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("18")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.8000")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("7.0000")]),s._v(" │ c     │ c      │ b     │ eight\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("11")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.1000")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1.0000")]),s._v(" │ a     │ b      │ c     │ first\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("9")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("19")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.9000")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("8.0000")]),s._v(" │ c     │ c      │ b     │ ninth\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.0000")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("9.0000")]),s._v(" │ c     │ c      │ b     │ ninth\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("12")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.2000")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1.0000")]),s._v(" │ a     │ b      │ c     │ second\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("14")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.4000")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3.0000")]),s._v(" │ b     │ a      │ c     │ second\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("16")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.6000")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5.0000")]),s._v(" │ b     │ a      │ a     │ second\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("7")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("13")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.3000")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2.0000")]),s._v(" │ a     │ b      │ c     │ third\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("15")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.5000")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4.0000")]),s._v(" │ b     │ a      │ a     │ third\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("9")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("7")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("17")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.7000")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6.0000")]),s._v(" │ b     │ c      │ a     │ third\n───┴───────┴───────┴─────────┴─────────┴───────┴────────┴───────┴────────\n")])])]),t("p",[s._v("最后，我们可以通过在标记的索引中设置一个新值来创建新的系列。请看下一条命令：")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("let")]),s._v(" indices "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" dfr to-df"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$df")]),s._v(".int_1 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" dfr set-with-idx "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("123")]),s._v(" --indices "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$indices")]),s._v("\n\n───┬───────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# │ int_1")]),s._v("\n───┼───────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │   "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("123")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" │   "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("123")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("7")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("7")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("9")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("9")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("\n───┴───────\n")])])]),t("h2",{attrs:{id:"唯一值"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#唯一值"}},[s._v("#")]),s._v(" 唯一值")]),s._v(" "),t("p",[s._v("另一个可以用"),t("code",[s._v("Series")]),s._v("完成的操作是在一个列表或列中搜索唯一值。让我们再次使用我们创建的第一个 DataFrame 来测试这些操作。")]),s._v(" "),t("p",[s._v("第一个也是最常见的操作是"),t("code",[s._v("value_counts")]),s._v("。这个命令计算出一个系列中存在的唯一值的数量。例如，我们可以用它来计算 "),t("code",[s._v("first")]),s._v(" 列各值的出现次数：")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$df")]),s._v(".first "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" dfr value-counts\n\n───┬───────┬────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# │ first │ counts")]),s._v("\n───┼───────┼────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │ b     │      "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" │ c     │      "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" │ a     │      "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v("\n───┴───────┴────────\n")])])]),t("p",[s._v("正如预期的那样，该命令返回一个新的 DataFrame，可以用来做更多的查询。")]),s._v(" "),t("p",[s._v("继续我们对 "),t("code",[s._v("Series")]),s._v(" 的探索，我们要做的下一件事是只从一个系列中获得唯一值，像这样：")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$df")]),s._v(".first "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" dfr unique\n\n───┬───────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# │ first")]),s._v("\n───┼───────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │ c\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" │ b\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" │ a\n───┴───────\n")])])]),t("p",[s._v("或者我们可以得到一个掩码，用来过滤出数据唯一或重复的行。例如，我们可以选择列 "),t("code",[s._v("word")]),s._v(" 中含唯一值的行：")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$df")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" dfr filter-with "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$df")]),s._v(".word "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" dfr is-unique"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n───┬───────┬───────┬─────────┬─────────┬───────┬────────┬───────┬───────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# │ int_1 │ int_2 │ float_1 │ float_2 │ first │ second │ third │ word")]),s._v("\n───┼───────┼───────┼─────────┼─────────┼───────┼────────┼───────┼───────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("11")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.1000")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1.0000")]),s._v(" │ a     │ b      │ c     │ first\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("18")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.8000")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("7.0000")]),s._v(" │ c     │ c      │ b     │ eight\n───┴───────┴───────┴─────────┴─────────┴───────┴────────┴───────┴───────\n")])])]),t("p",[s._v("或所有含重复值的行：")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$df")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" dfr filter-with "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("$df")]),s._v(".word "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v(" dfr is-duplicated"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n───┬───────┬───────┬─────────┬─────────┬───────┬────────┬───────┬────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# │ int_1 │ int_2 │ float_1 │ float_2 │ first │ second │ third │  word")]),s._v("\n───┼───────┼───────┼─────────┼─────────┼───────┼────────┼───────┼────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("12")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.2000")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1.0000")]),s._v(" │ a     │ b      │ c     │ second\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("13")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.3000")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2.0000")]),s._v(" │ a     │ b      │ c     │ third\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("14")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.4000")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3.0000")]),s._v(" │ b     │ a      │ c     │ second\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("15")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.5000")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4.0000")]),s._v(" │ b     │ a      │ a     │ third\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("16")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.6000")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5.0000")]),s._v(" │ b     │ a      │ a     │ second\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("7")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("17")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.7000")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6.0000")]),s._v(" │ b     │ c      │ a     │ third\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("9")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("19")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.9000")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("8.0000")]),s._v(" │ c     │ c      │ b     │ ninth\n "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("7")]),s._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.0000")]),s._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("9.0000")]),s._v(" │ c     │ c      │ b     │ ninth\n───┴───────┴───────┴─────────┴─────────┴───────┴────────┴───────┴────────\n")])])]),t("h2",{attrs:{id:"dataframe-命令"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#dataframe-命令"}},[s._v("#")]),s._v(" Dataframe 命令")]),s._v(" "),t("p",[s._v("到目前为止，我们已经看到了很多可以使用 "),t("code",[s._v("DataFrame")]),s._v(" 相关命令的操作。然而，到目前为止，我们所使用的命令并不包括所有可用来处理数据的命令，请放心，随着该功能的稳定，还会有更多的命令。")]),s._v(" "),t("p",[s._v("下表列出了可用的"),t("code",[s._v("DataFrame")]),s._v("命令及其描述，并尽可能显示其类似的 Nushell 命令。")]),s._v(" "),t("table",[t("thead",[t("tr",[t("th",[s._v("命令名")]),s._v(" "),t("th",[s._v("应用于")]),s._v(" "),t("th",[s._v("描述")]),s._v(" "),t("th",[s._v("Nushell 类似命令")])])]),s._v(" "),t("tbody",[t("tr",[t("td",[s._v("aggregate")]),s._v(" "),t("td",[s._v("DataFrame, GroupBy, Series")]),s._v(" "),t("td",[s._v("在一个 DataFrame、GroupBy 或系列对象上执行聚合操作")]),s._v(" "),t("td",[s._v("math")])]),s._v(" "),t("tr",[t("td",[s._v("all-false")]),s._v(" "),t("td",[s._v("Series")]),s._v(" "),t("td",[s._v("如果所有的值都是假的，则返回真")]),s._v(" "),t("td")]),s._v(" "),t("tr",[t("td",[s._v("all-true")]),s._v(" "),t("td",[s._v("Series")]),s._v(" "),t("td",[s._v("如果所有的值都是真的，则返回真")]),s._v(" "),t("td",[s._v("all?")])]),s._v(" "),t("tr",[t("td",[s._v("arg-max")]),s._v(" "),t("td",[s._v("Series")]),s._v(" "),t("td",[s._v("返回系列中最大值的索引")]),s._v(" "),t("td")]),s._v(" "),t("tr",[t("td",[s._v("arg-min")]),s._v(" "),t("td",[s._v("Series")]),s._v(" "),t("td",[s._v("返回系列中最小值的索引")]),s._v(" "),t("td")]),s._v(" "),t("tr",[t("td",[s._v("arg-sort")]),s._v(" "),t("td",[s._v("Series")]),s._v(" "),t("td",[s._v("返回排序后的系列的索引")]),s._v(" "),t("td")]),s._v(" "),t("tr",[t("td",[s._v("arg-true")]),s._v(" "),t("td",[s._v("Series")]),s._v(" "),t("td",[s._v("返回值为真的索引")]),s._v(" "),t("td")]),s._v(" "),t("tr",[t("td",[s._v("arg-unique")]),s._v(" "),t("td",[s._v("Series")]),s._v(" "),t("td",[s._v("返回唯一值的索引")]),s._v(" "),t("td")]),s._v(" "),t("tr",[t("td",[s._v("column")]),s._v(" "),t("td",[s._v("DataFrame")]),s._v(" "),t("td",[s._v("将选定的列作为系列返回")]),s._v(" "),t("td",[s._v("get")])]),s._v(" "),t("tr",[t("td",[s._v("count-null")]),s._v(" "),t("td",[s._v("Series")]),s._v(" "),t("td",[s._v("计算空值")]),s._v(" "),t("td")]),s._v(" "),t("tr",[t("td",[s._v("count-unique")]),s._v(" "),t("td",[s._v("Series")]),s._v(" "),t("td",[s._v("计算唯一值")]),s._v(" "),t("td")]),s._v(" "),t("tr",[t("td",[s._v("drop")]),s._v(" "),t("td",[s._v("DataFrame")]),s._v(" "),t("td",[s._v("通过删除选定的列来创建一个新的 DataFrame")]),s._v(" "),t("td",[s._v("drop")])]),s._v(" "),t("tr",[t("td",[s._v("drop-duplicates")]),s._v(" "),t("td",[s._v("DataFrame")]),s._v(" "),t("td",[s._v("删除 DataFrame 中的重复值")]),s._v(" "),t("td")]),s._v(" "),t("tr",[t("td",[s._v("drop-nulls")]),s._v(" "),t("td",[s._v("DataFrame, Series")]),s._v(" "),t("td",[s._v("丢弃 DataFrame 中的空值")]),s._v(" "),t("td")]),s._v(" "),t("tr",[t("td",[s._v("dtypes")]),s._v(" "),t("td",[s._v("DataFrame")]),s._v(" "),t("td",[s._v("显示 DataFrame 的数据类型")]),s._v(" "),t("td")]),s._v(" "),t("tr",[t("td",[s._v("filter-with")]),s._v(" "),t("td",[s._v("DataFrame")]),s._v(" "),t("td",[s._v("使用 Mask 作为参考来过滤 DataFrame")]),s._v(" "),t("td")]),s._v(" "),t("tr",[t("td",[s._v("first")]),s._v(" "),t("td",[s._v("DataFrame")]),s._v(" "),t("td",[s._v("用第一行创建新的 DataFrame")]),s._v(" "),t("td",[s._v("first")])]),s._v(" "),t("tr",[t("td",[s._v("get")]),s._v(" "),t("td",[s._v("DataFrame")]),s._v(" "),t("td",[s._v("用选定的列创建 DataFrame")]),s._v(" "),t("td",[s._v("get")])]),s._v(" "),t("tr",[t("td",[s._v("group-by")]),s._v(" "),t("td",[s._v("DataFrame")]),s._v(" "),t("td",[s._v("创建一个 GroupBy 对象，可用于其他聚合")]),s._v(" "),t("td",[s._v("group-by")])]),s._v(" "),t("tr",[t("td",[s._v("is-duplicated")]),s._v(" "),t("td",[s._v("Series")]),s._v(" "),t("td",[s._v("创建表示重复值的 Mask")]),s._v(" "),t("td")]),s._v(" "),t("tr",[t("td",[s._v("is-in")]),s._v(" "),t("td",[s._v("Series")]),s._v(" "),t("td",[s._v("检查一个系列的元素是否包含在右边的系列中")]),s._v(" "),t("td",[s._v("in")])]),s._v(" "),t("tr",[t("td",[s._v("is-not-null")]),s._v(" "),t("td",[s._v("Series")]),s._v(" "),t("td",[s._v("创建值为非空的 Mask")]),s._v(" "),t("td")]),s._v(" "),t("tr",[t("td",[s._v("is-null")]),s._v(" "),t("td",[s._v("Series")]),s._v(" "),t("td",[s._v("创建值为空的 Mask")]),s._v(" "),t("td",[t("code",[s._v("<column_name> == $nothing")])])]),s._v(" "),t("tr",[t("td",[s._v("is-unique")]),s._v(" "),t("td",[s._v("Series")]),s._v(" "),t("td",[s._v("创建表示唯一值的 Mask")]),s._v(" "),t("td")]),s._v(" "),t("tr",[t("td",[s._v("join")]),s._v(" "),t("td",[s._v("DataFrame")]),s._v(" "),t("td",[s._v("使用列作为参考来连接一个 DataFrame")]),s._v(" "),t("td")]),s._v(" "),t("tr",[t("td",[s._v("last")]),s._v(" "),t("td",[s._v("DataFrame")]),s._v(" "),t("td",[s._v("用最后几行创建新的 DataFrame")]),s._v(" "),t("td",[s._v("last")])]),s._v(" "),t("tr",[t("td",[s._v("list")]),s._v(" "),t("td"),s._v(" "),t("td",[s._v("列出已存储的 DataFrame")]),s._v(" "),t("td")]),s._v(" "),t("tr",[t("td",[s._v("melt")]),s._v(" "),t("td",[s._v("DataFrame")]),s._v(" "),t("td",[s._v("将一个 DataFrame 从宽格式转为长格式")]),s._v(" "),t("td")]),s._v(" "),t("tr",[t("td",[s._v("not")]),s._v(" "),t("td",[s._v("Series Inverts boolean mask")]),s._v(" "),t("td"),s._v(" "),t("td")]),s._v(" "),t("tr",[t("td",[s._v("open")]),s._v(" "),t("td"),s._v(" "),t("td",[s._v("从 csv 文件中加载 DataFrame")]),s._v(" "),t("td",[s._v("open")])]),s._v(" "),t("tr",[t("td",[s._v("pivot")]),s._v(" "),t("td",[s._v("GroupBy")]),s._v(" "),t("td",[s._v("在 GroupBy 对象上执行透视操作")]),s._v(" "),t("td",[s._v("pivot")])]),s._v(" "),t("tr",[t("td",[s._v("rename")]),s._v(" "),t("td",[s._v("Series")]),s._v(" "),t("td",[s._v("重命名一个系列")]),s._v(" "),t("td",[s._v("rename")])]),s._v(" "),t("tr",[t("td",[s._v("sample")]),s._v(" "),t("td",[s._v("DataFrame")]),s._v(" "),t("td",[s._v("创建样本 DataFrame")]),s._v(" "),t("td")]),s._v(" "),t("tr",[t("td",[s._v("select")]),s._v(" "),t("td",[s._v("DataFrame")]),s._v(" "),t("td",[s._v("用选定的列创建一个新的 DataFrame")]),s._v(" "),t("td",[s._v("select")])]),s._v(" "),t("tr",[t("td",[s._v("set")]),s._v(" "),t("td",[s._v("Series")]),s._v(" "),t("td",[s._v("在给定的 Mask 为真时设置值")]),s._v(" "),t("td")]),s._v(" "),t("tr",[t("td",[s._v("set-with-idx")]),s._v(" "),t("td",[s._v("Series")]),s._v(" "),t("td",[s._v("设置给定索引中的值")]),s._v(" "),t("td")]),s._v(" "),t("tr",[t("td",[s._v("shift")]),s._v(" "),t("td",[s._v("Series")]),s._v(" "),t("td",[s._v("将值移到一个给定的时段")]),s._v(" "),t("td")]),s._v(" "),t("tr",[t("td",[s._v("show")]),s._v(" "),t("td",[s._v("DataFrame")]),s._v(" "),t("td",[s._v("将 DataFrame 的一个部分转换为一个表或列表值")]),s._v(" "),t("td")]),s._v(" "),t("tr",[t("td",[s._v("slice")]),s._v(" "),t("td",[s._v("DataFrame")]),s._v(" "),t("td",[s._v("从行的切片中创建新的 DataFrame")]),s._v(" "),t("td")]),s._v(" "),t("tr",[t("td",[s._v("sort")]),s._v(" "),t("td",[s._v("DataFrame, Series")]),s._v(" "),t("td",[s._v("创建新的排序 DataFrame 或系列")]),s._v(" "),t("td",[s._v("sort")])]),s._v(" "),t("tr",[t("td",[s._v("take")]),s._v(" "),t("td",[s._v("DataFrame, Series")]),s._v(" "),t("td",[s._v("使用给定的索引创建新的 DataFrame")]),s._v(" "),t("td")]),s._v(" "),t("tr",[t("td",[s._v("to-csv")]),s._v(" "),t("td",[s._v("DataFrame")]),s._v(" "),t("td",[s._v("将 DataFrame 保存为 csv 文件")]),s._v(" "),t("td",[s._v("to csv")])]),s._v(" "),t("tr",[t("td",[s._v("to-df")]),s._v(" "),t("td"),s._v(" "),t("td",[s._v("将一个管道里的表或列表转换为 DataFrame")]),s._v(" "),t("td")]),s._v(" "),t("tr",[t("td",[s._v("to-dummies")]),s._v(" "),t("td",[s._v("DataFrame")]),s._v(" "),t("td",[s._v("创建一个带有假值的新 DataFrame")]),s._v(" "),t("td")]),s._v(" "),t("tr",[t("td",[s._v("to-parquet")]),s._v(" "),t("td",[s._v("DataFrame")]),s._v(" "),t("td",[s._v("将 DataFrame 保存到 parquet 文件中")]),s._v(" "),t("td")]),s._v(" "),t("tr",[t("td",[s._v("unique")]),s._v(" "),t("td",[s._v("Series")]),s._v(" "),t("td",[s._v("返回一个系列中的唯一值")]),s._v(" "),t("td",[s._v("uniq")])]),s._v(" "),t("tr",[t("td",[s._v("value-counts")]),s._v(" "),t("td",[s._v("Series")]),s._v(" "),t("td",[s._v("返回一个带有系列中唯一值的计数的 DataFrame")]),s._v(" "),t("td")]),s._v(" "),t("tr",[t("td",[s._v("where")]),s._v(" "),t("td",[s._v("DataFrame")]),s._v(" "),t("td",[s._v("过滤 DataFrame 以符合条件")]),s._v(" "),t("td",[s._v("where")])]),s._v(" "),t("tr",[t("td",[s._v("with-column")]),s._v(" "),t("td",[s._v("DataFrame")]),s._v(" "),t("td",[s._v("在 DataFrame 中添加一个系列")]),s._v(" "),t("td",[t("code",[s._v("insert <column_name> <value> | upsert <column_name> { <new_value> }")])])])])]),s._v(" "),t("h2",{attrs:{id:"dataframes-的未来"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#dataframes-的未来"}},[s._v("#")]),s._v(" DataFrames 的未来")]),s._v(" "),t("p",[s._v("我们希望在本页结束时，你已经牢固掌握了如何使用 DataFrame 相关命令。正如你所看到的，它们提供了强大的操作，可以帮助你更快更原生地处理数据。")]),s._v(" "),t("p",[s._v('然而，DataFrames 的未来仍然是非常实验性的，随着这些命令的成熟，新的命令和利用这些命令的工具将被加入。例如，DataFrames 的下一步是引入惰性 DataFrames，这将允许你定义复杂的数据操作，这些操作将在你决定 "'),t("strong",[s._v("完成")]),s._v('" 这个管道时才被执行。这将使 Nushell 有机会选择最佳计划来查询你所要求的数据。')]),s._v(" "),t("p",[s._v("请继续访问本书，以查看 DataFrames 的最新情况，以及它们如何帮助你更快更有效地处理数据。")])])}),[],!1,null,null,null);a.default=n.exports}}]);