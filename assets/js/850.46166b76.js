(window.webpackJsonp=window.webpackJsonp||[]).push([[850],{1367:function(a,s,t){"use strict";t.r(s);var e=t(35),n=Object(e.a)({},(function(){var a=this,s=a.$createElement,t=a._self._c||s;return t("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[t("h1",{attrs:{id:"dataframes"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#dataframes"}},[a._v("#")]),a._v(" Dataframes")]),a._v(" "),t("blockquote",[t("p",[a._v("Note. The dataframe commands are available from version 0.33.1 onwards")])]),a._v(" "),t("p",[a._v("As we have seen so far, nushell makes working with data its main priority.\n"),t("code",[a._v("Lists")]),a._v(" and "),t("code",[a._v("Tables")]),a._v(" are there to help you cycle through values in order to\nperform multiple operations or find data in a breeze. However, there are\ncertain operations where a row-based data layout is not the most efficient way\nto process data, especially when working with extremely large files. Operations\nlike group-by or join using large datasets can be costly memory-wise, and may\nlead to large computation times if they are not done using the appropriate\ndata format.")]),a._v(" "),t("p",[a._v("For this reason, the "),t("code",[a._v("DataFrame")]),a._v(" structure was introduced to nushell. A\n"),t("code",[a._v("DataFrame")]),a._v(" stores its data in a columnar format using as its base the "),t("a",{attrs:{href:"https://arrow.apache.org/",target:"_blank",rel:"noopener noreferrer"}},[a._v("Apache\nArrow"),t("OutboundLink")],1),a._v(" specification, and uses\n"),t("a",{attrs:{href:"https://github.com/pola-rs/polars",target:"_blank",rel:"noopener noreferrer"}},[a._v("Polars"),t("OutboundLink")],1),a._v(" as the motor for performing\nextremely "),t("a",{attrs:{href:"https://h2oai.github.io/db-benchmark/",target:"_blank",rel:"noopener noreferrer"}},[a._v("fast columnar operations"),t("OutboundLink")],1),a._v(".")]),a._v(" "),t("p",[a._v("You may be wondering now how fast this combo could be, and how could it make\nworking with data easier and more reliable. For this reason, let's start this\npage by presenting benchmarks on common operations that are done when\nprocessing data.")]),a._v(" "),t("h2",{attrs:{id:"benchmark-comparisons"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#benchmark-comparisons"}},[a._v("#")]),a._v(" Benchmark comparisons")]),a._v(" "),t("p",[a._v("For this little benchmark exercise we will be comparing native nushell\ncommands, dataframe nushell commands and "),t("a",{attrs:{href:"https://pandas.pydata.org/",target:"_blank",rel:"noopener noreferrer"}},[a._v("Python\nPandas"),t("OutboundLink")],1),a._v(" commands. For the time being don't pay too\nmuch attention to the "),t("code",[a._v("dataframe")]),a._v(" commands. They will be explained in later\nsections of this page.")]),a._v(" "),t("blockquote",[t("p",[a._v("System Details: The benchmarks presented in this section were run using a\nmachine with a processor Intel(R) Core(TM) i7-10710U (CPU @1.10GHz 1.61 GHz)\nand 16 gb of RAM.")]),a._v(" "),t("p",[a._v("All examples where run on Nushell version 0.33.1.")])]),a._v(" "),t("h3",{attrs:{id:"file-information"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#file-information"}},[a._v("#")]),a._v(" File information")]),a._v(" "),t("p",[a._v("The file that we will be using for the benchmarks is the\n"),t("a",{attrs:{href:"https://www.stats.govt.nz/assets/Uploads/New-Zealand-business-demography-statistics/New-Zealand-business-demography-statistics-At-February-2020/Download-data/Geographic-units-by-industry-and-statistical-area-2000-2020-descending-order-CSV.zip",target:"_blank",rel:"noopener noreferrer"}},[a._v("New Zealand business demography"),t("OutboundLink")],1),a._v(" dataset.\nFeel free to download it if you want to follow these tests.")]),a._v(" "),t("p",[a._v("The dataset has 5 columns and 5,429,252 rows. We can check that by using the\n"),t("code",[a._v("dataframe list")]),a._v(" command:")]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("let")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("df")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("dataframe "),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("open")]),a._v(" ."),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("Data7602DescendingYearOrder.csv"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" dataframe list\n\n───┬──────┬─────────┬─────────┬───────────────────────────────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# │ name │  rows   │ columns │             location")]),a._v("\n───┼──────┼─────────┼─────────┼───────────────────────────────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$df")]),a._v("  │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("5429252")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("5")]),a._v("       │ ."),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("Data7602DescendingYearOrder.csv\n───┴──────┴─────────┴─────────┴───────────────────────────────────\n")])])]),t("p",[a._v("We can have a look at the first lines of the file using "),t("code",[a._v("dataframe first")]),a._v(":")]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$df")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" dataframe first\n\n───┬──────────┬─────────┬──────┬───────────┬──────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# │ anzsic06 │  Area   │ year │ geo_count │ ec_count")]),a._v("\n───┼──────────┼─────────┼──────┼───────────┼──────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │ A        │ A100100 │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2000")]),a._v(" │        "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("96")]),a._v(" │      "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("130")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" │ A        │ A100200 │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2000")]),a._v(" │       "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("198")]),a._v(" │      "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("110")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(" │ A        │ A100300 │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2000")]),a._v(" │        "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("42")]),a._v(" │       "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("25")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),a._v(" │ A        │ A100400 │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2000")]),a._v(" │        "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("66")]),a._v(" │       "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("40")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("4")]),a._v(" │ A        │ A100500 │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2000")]),a._v(" │        "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("63")]),a._v(" │       "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("40")]),a._v("\n───┴──────────┴─────────┴──────┴───────────┴──────────\n")])])]),t("p",[a._v("...and finally, we can get an idea of the inferred datatypes:")]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$df")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" dataframe dtypes\n\n───┬───────────┬───────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# │  column   │ dtype")]),a._v("\n───┼───────────┼───────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │ anzsic06  │ str\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" │ Area      │ str\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(" │ year      │ i64\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),a._v(" │ geo_count │ i64\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("4")]),a._v(" │ ec_count  │ i64\n───┴───────────┴───────\n")])])]),t("h3",{attrs:{id:"loading-the-file"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#loading-the-file"}},[a._v("#")]),a._v(" Loading the file")]),a._v(" "),t("p",[a._v("Let's start by comparing loading times between the various methods. First, we\nwill load the data using nushell load command:")]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" benchmark "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v("open ."),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("Data7602DescendingYearOrder.csv"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n\n───┬─────────────────────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# │        real time")]),a._v("\n───┼─────────────────────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │ 30sec 479ms 614us 400ns\n───┴─────────────────────────\n")])])]),t("p",[a._v("Loading the file using native nushell commands took 30 seconds. Not bad for\nloading five million records in order to do data analysis. But we can do a bit\nbetter than that.")]),a._v(" "),t("p",[a._v("Let's now use Pandas. We are going to use the next script to load the file:")]),a._v(" "),t("div",{staticClass:"language-python extra-class"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("import")]),a._v(" pandas "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("as")]),a._v(" pd\n\ndf "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" pd"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("read_csv"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"Data7602DescendingYearOrder.csv"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n")])])]),t("p",[a._v("And the benchmark for it is:")]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" benchmark "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v("python load.py"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n\n───┬───────────────────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# │       real time")]),a._v("\n───┼───────────────────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │ 2sec 91ms 872us 900ns\n───┴───────────────────────\n")])])]),t("p",[a._v("That is a great improvement, from 30 seconds to 2 seconds. Nicely done, Pandas!")]),a._v(" "),t("p",[a._v("Probably we can load the data a bit faster. This time we will use nushell's\n"),t("code",[a._v("dataframe open")]),a._v(" command:")]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" benchmark "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v("dataframe "),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("open")]),a._v(" ."),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("Data7602DescendingYearOrder.csv"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n\n───┬───────────────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# │     real time")]),a._v("\n───┼───────────────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │ 601ms 700us 700ns\n───┴───────────────────\n")])])]),t("p",[a._v("This time it took us 0.6 seconds. Not bad at all.")]),a._v(" "),t("h3",{attrs:{id:"group-by-comparison"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#group-by-comparison"}},[a._v("#")]),a._v(" Group-by comparison")]),a._v(" "),t("p",[a._v("Lets do a slightly more complex operation this time. We are going to group the\ndata by year, and add groups using the column "),t("code",[a._v("geo_count")]),a._v(".")]),a._v(" "),t("p",[a._v("Again, we are going to start with nushell native command.")]),a._v(" "),t("blockquote",[t("p",[a._v("Note: If you want to run this example, be aware that the next command will\nuse a large amount of memory. This may affect the performance of you system\nwhile this is being executed.")])]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" benchmark "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v("\n\t"),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("open")]),a._v(" ."),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("Data7602DescendingYearOrder.csv\n\t"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" group-by year\n\t"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" pivot header rows\n\t"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" update rows "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v(" get rows "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" math "),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("sum")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n\t"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" flatten\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n\n───┬────────────────────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# │       real time")]),a._v("\n───┼────────────────────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │ 6min 30sec 622ms 312us\n───┴────────────────────────\n")])])]),t("p",[a._v("So, six minutes to perform this aggregated operation.")]),a._v(" "),t("p",[a._v("Let's try the same operation in pandas:")]),a._v(" "),t("div",{staticClass:"language-python extra-class"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("import")]),a._v(" pandas "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("as")]),a._v(" pd\n\ndf "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" pd"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("read_csv"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"Data7602DescendingYearOrder.csv"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\nres "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" df"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("groupby"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"year"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"geo_count"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[a._v("sum")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("res"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n")])])]),t("p",[a._v("And the result from the benchmark is:")]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" benchmark "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v("python ."),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("load.py"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n\n───┬────────────────────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# │       real time")]),a._v("\n───┼────────────────────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │ 1sec 966ms 954us 800ns\n───┴────────────────────────\n")])])]),t("p",[a._v("Not bad at all. Again, pandas managed to get it done in a fraction of the time.")]),a._v(" "),t("p",[a._v("To finish the comparison, let's try nushell dataframes. We are going to put\nall the operations in one "),t("code",[a._v("nu")]),a._v(" file, to make sure we are doing similar\noperations:")]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("let")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("df")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("dataframe "),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("open")]),a._v(" Data7602DescendingYearOrder.csv"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("let")]),a._v(" res "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$df")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" dataframe group-by year "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" dataframe aggregate "),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("sum")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" dataframe "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("select")]),a._v(" geo_count"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$res")]),a._v("\n")])])]),t("p",[a._v("and the benchmark with dataframes is:")]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" benchmark "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v("source load.nu"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v("\n\n───┬───────────────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# │     real time")]),a._v("\n───┼───────────────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │ 557ms 658us 500ns\n───┴───────────────────\n")])])]),t("p",[a._v("Luckily nushell dataframes managed to halve the time again. Isn't that great?")]),a._v(" "),t("p",[a._v("As you can see, Nushell's "),t("code",[a._v("Dataframe")]),a._v(" commands are as fast as the most common\ntools that exist today to do data analysis. The commands that are included in\nthis release have the potential to become your go-to tool for doing data\nanalysis. By composing complex nushell pipelines, you can extract information\nfrom data in a reliable way.")]),a._v(" "),t("h2",{attrs:{id:"working-with-dataframes"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#working-with-dataframes"}},[a._v("#")]),a._v(" Working with Dataframes")]),a._v(" "),t("p",[a._v("After seeing a glimpse of the things that can be done with "),t("code",[a._v("Dataframe")]),a._v("\ncommands, now it is time to start testing them. To begin let's create a sample\nCSV file that will become our sample dataframe that we will be using along with\nthe examples. In your favorite file editor paste the next lines to create out\nsample csv file.")]),a._v(" "),t("div",{staticClass:"language-csv extra-class"},[t("pre",{pre:!0,attrs:{class:"language-csv"}},[t("code",[t("span",{pre:!0,attrs:{class:"token value"}},[a._v("int_1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("int_2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("float_1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("float_2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("first")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("second")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("third")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("word")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("11")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("0.1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("1.0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("a")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("b")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("c")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("first")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("12")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("0.2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("1.0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("a")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("b")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("c")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("second")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("3")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("13")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("0.3")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("2.0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("a")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("b")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("c")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("third")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("4")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("14")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("0.4")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("3.0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("b")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("a")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("c")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("second")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("15")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("0.5")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("4.0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("b")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("a")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("a")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("third")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("6")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("16")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("0.6")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("5.0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("b")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("a")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("a")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("second")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("7")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("17")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("0.7")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("6.0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("b")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("c")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("a")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("third")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("8")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("18")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("0.8")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("7.0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("c")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("c")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("b")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("eight")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("9")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("19")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("0.9")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("8.0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("c")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("c")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("b")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("ninth")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("10")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("0.0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("9.0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("c")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("c")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("b")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),t("span",{pre:!0,attrs:{class:"token value"}},[a._v("ninth")]),a._v("\n")])])]),t("p",[a._v("Save the file and name it however you want to, for the sake of these examples\nthe file will be called "),t("code",[a._v("test_small.csv")]),a._v(".")]),a._v(" "),t("p",[a._v("Now, to read that file as a dataframe use the "),t("code",[a._v("dataframe open")]),a._v(" command like\nthis:")]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("let")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("df")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("dataframe "),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("open")]),a._v(" test_small.csv"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n")])])]),t("p",[a._v("This should create the value "),t("code",[a._v("df")]),a._v(" in memory which holds the data we just\ncreated.")]),a._v(" "),t("blockquote",[t("p",[a._v("Note: The command "),t("code",[a._v("dataframes open")]),a._v(" can read either "),t("strong",[a._v("csv")]),a._v(" or "),t("strong",[a._v("parquet")]),a._v("\nfiles.")])]),a._v(" "),t("p",[a._v("To see all the dataframes that are stored in memory you can use")]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" dataframe list\n\n───┬──────┬──────┬─────────┬────────────────────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# │ name │ rows │ columns │        location")]),a._v("\n───┼──────┼──────┼─────────┼────────────────────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$df")]),a._v("  │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("10")]),a._v("   │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("8")]),a._v("       │ "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("test_small.csv\n───┴──────┴──────┴─────────┴────────────────────────\n")])])]),t("p",[a._v("As you can see, the command shows the created dataframes together with basic\ninformation about them.")]),a._v(" "),t("p",[a._v("And if you want to see a preview of the loaded dataframe you can send the\ndataframe variable to the stream")]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$df")]),a._v("\n\n───┬───────┬───────┬─────────┬─────────┬───────┬────────┬───────┬────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# │ int_1 │ int_2 │ float_1 │ float_2 │ first │ second │ third │  word")]),a._v("\n───┼───────┼───────┼─────────┼─────────┼───────┼────────┼───────┼────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("11")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.1000")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1.0000")]),a._v(" │ a     │ b      │ c     │ first\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("12")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.2000")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1.0000")]),a._v(" │ a     │ b      │ c     │ second\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("13")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.3000")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2.0000")]),a._v(" │ a     │ b      │ c     │ third\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("4")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("14")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.4000")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("3.0000")]),a._v(" │ b     │ a      │ c     │ second\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("4")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("15")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.5000")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("4.0000")]),a._v(" │ b     │ a      │ a     │ third\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("5")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("6")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("16")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.6000")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("5.0000")]),a._v(" │ b     │ a      │ a     │ second\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("6")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("7")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("17")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.7000")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("6.0000")]),a._v(" │ b     │ c      │ a     │ third\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("7")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("8")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("18")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.8000")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("7.0000")]),a._v(" │ c     │ c      │ b     │ eight\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("8")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("9")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("19")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.9000")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("8.0000")]),a._v(" │ c     │ c      │ b     │ ninth\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("9")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("10")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.0000")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("9.0000")]),a._v(" │ c     │ c      │ b     │ ninth\n───┴───────┴───────┴─────────┴─────────┴───────┴────────┴───────┴────────\n")])])]),t("p",[a._v("With the dataframe in memory we can start doing column operations with the\n"),t("code",[a._v("DataFrame")])]),a._v(" "),t("blockquote",[t("p",[a._v("Note: If you want to see all the dataframe commands that are available you\ncan use "),t("code",[a._v("help dataframe")])])]),a._v(" "),t("h2",{attrs:{id:"basic-aggregations"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#basic-aggregations"}},[a._v("#")]),a._v(" Basic aggregations")]),a._v(" "),t("p",[a._v("Let's start with basic aggregations on the dataframe. Let's sum all the columns\nthat exist in "),t("code",[a._v("df")]),a._v(" by using the "),t("code",[a._v("aggregate")]),a._v(" command")]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$df")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" dataframe aggregate "),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("sum")]),a._v("\n\n───┬───────┬───────┬─────────┬─────────┬───────┬────────┬───────┬──────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# │ int_1 │ int_2 │ float_1 │ float_2 │ first │ second │ third │ word")]),a._v("\n───┼───────┼───────┼─────────┼─────────┼───────┼────────┼───────┼──────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("40")]),a._v(" │   "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("145")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("4.5000")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("46.0000")]),a._v(" │       │        │       │\n───┴───────┴───────┴─────────┴─────────┴───────┴────────┴───────┴──────\n")])])]),t("p",[a._v("As you can see, the aggregate function computes the sum for those columns where\na sum makes sense. If you want to filter out the text column, you can select\nthe columns you want by using the "),t("code",[a._v("select")]),a._v(" command")]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$df")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" dataframe aggregate "),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("sum")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" dataframe "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("select")]),a._v(" int_1 int_2 float_1 float_2\n\n───┬───────┬───────┬─────────┬─────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# │ int_1 │ int_2 │ float_1 │ float_2")]),a._v("\n───┼───────┼───────┼─────────┼─────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("40")]),a._v(" │   "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("145")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("4.5000")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("46.0000")]),a._v("\n───┴───────┴───────┴─────────┴─────────\n")])])]),t("p",[a._v("you can even store the result from this aggregation as you would store any\nother nushell variable")]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("let")]),a._v(" res "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$df")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" dataframe aggregate "),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("sum")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" dataframe "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("select")]),a._v(" int_1 int_2 float_1 float_2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n")])])]),t("p",[a._v("and now we have two dataframes stored in memory")]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" dataframe list\n\n───┬──────┬──────┬─────────┬────────────────────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# │ name │ rows │ columns │        location")]),a._v("\n───┼──────┼──────┼─────────┼────────────────────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$df")]),a._v("  │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("10")]),a._v("   │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("8")]),a._v("       │ "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("test_small.csv\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$res")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v("    │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("4")]),a._v("       │ stream\n───┴──────┴──────┴─────────┴────────────────────────\n")])])]),t("p",[a._v("pretty neat, isn't it?")]),a._v(" "),t("p",[a._v("You can perform several aggregations on the dataframe in order to extract basic\ninformation from the dataframe and do basic data analysis on your brand new\ndataframe.")]),a._v(" "),t("h2",{attrs:{id:"joining-a-dataframe"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#joining-a-dataframe"}},[a._v("#")]),a._v(" Joining a DataFrame")]),a._v(" "),t("p",[a._v("It is also possible to join two dataframes using a column as reference. We are\ngoing to join our mini dataframe with another mini dataframe. Copy these lines\nin another file and create the corresponding dataframe (for these examples we\nare going to call it "),t("code",[a._v("test_small_a.csv")]),a._v(")")]),a._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v("int_1a,int_2,float_1,float_2,first\n9,14,0.4,3.0,a\n8,13,0.3,2.0,a\n7,12,0.2,1.0,a\n6,11,0.1,0.0,b\n")])])]),t("p",[a._v("We use the "),t("code",[a._v("dataframe open")]),a._v(" command to create the new variable")]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("let")]),a._v(" df_a "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("dataframe "),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("open")]),a._v(" test_small_a.csv"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n")])])]),t("p",[a._v("Now, with the second dataframe loaded in memory we can join them using the\ncolumn called "),t("code",[a._v("int_1")]),a._v(" from the left dataframe and the column "),t("code",[a._v("int_1a")]),a._v(" from the\nright dataframe")]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$df")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" dataframe "),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("join")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$df_a")]),a._v(" -l "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("int_1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" -r "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("int_1a"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n\n───┬───────┬───────┬─────────┬─────────┬───────┬────────┬───────┬─────────┬─────────────┬───────────────┬───────────────┬─────────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# │ int_1 │ int_2 │ float_1 │ float_2 │ first │ second │ third │  word   │ int_2_right │ float_1_right │ float_2_right │ first_right")]),a._v("\n───┼───────┼───────┼─────────┼─────────┼───────┼────────┼───────┼─────────┼─────────────┼───────────────┼───────────────┼─────────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("6")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("16")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.6000")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("5.0000")]),a._v(" │ b     │ a      │ a     │ second  │          "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("11")]),a._v(" │        "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.1000")]),a._v(" │        "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.0000")]),a._v(" │ b\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("7")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("17")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.7000")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("6.0000")]),a._v(" │ b     │ c      │ a     │ third   │          "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("12")]),a._v(" │        "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.2000")]),a._v(" │        "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1.0000")]),a._v(" │ a\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("8")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("18")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.8000")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("7.0000")]),a._v(" │ c     │ c      │ b     │ eight   │          "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("13")]),a._v(" │        "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.3000")]),a._v(" │        "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2.0000")]),a._v(" │ a\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("9")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("19")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.9000")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("8.0000")]),a._v(" │ c     │ c      │ b     │ ninth   │          "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("14")]),a._v(" │        "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.4000")]),a._v(" │        "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("3.0000")]),a._v(" │ a\n───┴───────┴───────┴─────────┴─────────┴───────┴────────┴───────┴─────────┴─────────────┴───────────────┴───────────────┴─────────────\n")])])]),t("blockquote",[t("p",[a._v("Note: In "),t("code",[a._v("Nu")]),a._v(" when a command has multiple arguments that are expecting\nmultiple values we use brackets "),t("code",[a._v("[]")]),a._v(" to enclose those values. In the case of\n"),t("code",[a._v("dataframe join")]),a._v(" we can join on multiple columns as long as they have the\nsame type, for example we could have done "),t("code",[a._v("$df | dataframe join $df_a -l [int_1 int_2] -r [int_1a int_2]")])])]),a._v(" "),t("p",[a._v("By default, the join command does an inner join, meaning that it will keep the\nrows where both dataframes share the same value. You can select a left join to\nkeep the missing rows from the left dataframe. You can also save this result\nin order to use it for further operations.")]),a._v(" "),t("h2",{attrs:{id:"dataframe-group-by"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#dataframe-group-by"}},[a._v("#")]),a._v(" DataFrame group-by")]),a._v(" "),t("p",[a._v("One of the most powerful operations that can be performed with a DataFrame is\nthe "),t("code",[a._v("group-by")]),a._v(". This command will allow you to perform aggregation operations\nbased on a grouping criteria. In nushell, a "),t("code",[a._v("GroupBy")]),a._v(" is a type of object that\ncan be stored and reused for multiple aggregations. This is quite handy, since\nthe creation of the grouped pairs is the most expensive operation while doing\ngroup-by and there is no need to repeat it if you are planning to do multiple\noperations with the same group condition.")]),a._v(" "),t("p",[a._v("To create a "),t("code",[a._v("GroupBy")]),a._v(" object you only need to use the "),t("code",[a._v("group-by")]),a._v(" command")]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("let")]),a._v(" group "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$df")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" dataframe group-by first"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$group")]),a._v("\n\n───┬──────────┬───────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# │ property │ value")]),a._v("\n───┼──────────┼───────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │ group by │ first\n───┴──────────┴───────\n")])])]),t("p",[a._v("When printing the "),t("code",[a._v("GroupBy")]),a._v(" object we can see the columns that are used as\ncriteria to group the dataframe. Using the "),t("code",[a._v("GroupBy")]),a._v(" we can aggregate the\ndataframe using multiple operations")]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$group")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" dataframe aggregate "),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("sum")]),a._v("\n\n───┬───────┬───────────┬───────────┬─────────────┬─────────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# │ first │ int_1     │ int_2     │ float_1     │ float_2")]),a._v("\n───┼───────┼───────────┼───────────┼─────────────┼─────────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │ a     │         "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("6")]),a._v(" │        "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("36")]),a._v(" │      "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.6000")]),a._v(" │      "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("4.0000")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" │ b     │        "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("17")]),a._v(" │        "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("62")]),a._v(" │      "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2.2000")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("18.0000")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(" │ c     │        "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("17")]),a._v(" │        "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("47")]),a._v(" │      "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1.7000")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("24.0000")]),a._v("\n───┴───────┴───────────┴───────────┴─────────────┴─────────────\n")])])]),t("p",[a._v("and using the same "),t("code",[a._v("GroupBy")]),a._v(" you can perform now another operation on the\nwhole dataframe, like "),t("code",[a._v("min")]),a._v(" in this case")]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$group")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" aggregate min\n\n───┬───────┬───────────┬───────────┬─────────────┬─────────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# │ first │ int_1     │ int_2     │ float_1     │ float_2")]),a._v("\n───┼───────┼───────────┼───────────┼─────────────┼─────────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │ a     │         "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" │        "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("11")]),a._v(" │      "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.1000")]),a._v(" │      "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1.0000")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" │ b     │         "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │        "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("14")]),a._v(" │      "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.4000")]),a._v(" │      "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("3.0000")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(" │ c     │         "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │        "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("10")]),a._v(" │      "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.0000")]),a._v(" │      "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("7.0000")]),a._v("\n───┴───────┴───────────┴───────────┴─────────────┴─────────────\n")])])]),t("p",[a._v("the created "),t("code",[a._v("GroupBy")]),a._v(" object is so handy that it can even be used as base for\npivoting a table. As an example, Lets use the column called "),t("code",[a._v("second")]),a._v(" as the\npivot column and the column "),t("code",[a._v("float_1")]),a._v(" as the value column")]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$group")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" dataframe pivot second float_1 "),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("sum")]),a._v("\n\n───┬───────┬────────┬────────┬────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# │ first │   b    │   a    │   c")]),a._v("\n───┼───────┼────────┼────────┼────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │ a     │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.6000")]),a._v(" │        │\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" │ c     │        │        │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1.7000")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(" │ b     │        │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1.5000")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.7000")]),a._v("\n───┴───────┴────────┴────────┴────────\n")])])]),t("blockquote",[t("p",[a._v("Note: a pivot operation is a way to aggregate data based on two columns. In\nthe previous example, the result of the pivot command produced a table that\nrepresents the sum of all the values in the column "),t("code",[a._v("float_1")]),a._v(" that are shared\nbetween columns "),t("code",[a._v("first")]),a._v(" (now the rows) and "),t("code",[a._v("second")]),a._v(" (now the columns). So,\nthe value of "),t("code",[a._v("1.5")]),a._v(" shown in row "),t("code",[a._v("b")]),a._v(" and column "),t("code",[a._v("a")]),a._v(" is the sum of all the\nfloats where the column "),t("code",[a._v("first")]),a._v(" is "),t("code",[a._v("b")]),a._v(" and column "),t("code",[a._v("second")]),a._v(" is "),t("code",[a._v("a")])])]),a._v(" "),t("p",[a._v("As you can see, the "),t("code",[a._v("GroupBy")]),a._v(" object is a very powerful variable and it is\nworthy it to keep in memory to keep exploring your dataset.")]),a._v(" "),t("h2",{attrs:{id:"creating-dataframes"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#creating-dataframes"}},[a._v("#")]),a._v(" Creating Dataframes")]),a._v(" "),t("p",[a._v("It is also possible to construct dataframes from basic nushell primitives, such\nas integers, decimals, or strings. Let's create a small dataframe using the\ncommand "),t("code",[a._v("to-df")]),a._v(".")]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("let")]),a._v(" a "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("a b"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(";")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("4")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("5")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("6")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" dataframe to-df"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$a")]),a._v("\n\n───┬───┬───\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# │ b │ a")]),a._v("\n───┼───┼───\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("4")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("6")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("5")]),a._v("\n───┴───┴───\n")])])]),t("blockquote",[t("p",[a._v("Note: For the time being, not all of Nushell primitives can be converted into\na dataframe. This will change in the future, as the dataframe feature matures")])]),a._v(" "),t("p",[a._v("We can append columns to a dataframe in order to create a new variable. As an\nexample, let's append two columns to our mini dataframe "),t("code",[a._v("$a")])]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("let")]),a._v(" a2 "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$a")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" dataframe with-column "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$a")]),a._v(".a --name a2 "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" dataframe with-column "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$a")]),a._v(".a --name a3"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n\n───┬───┬───┬────┬────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# │ b │ a │ a2 │ a3")]),a._v("\n───┼───┼───┼────┼────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("4")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("6")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("5")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("5")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("5")]),a._v("\n───┴───┴───┴────┴────\n")])])]),t("p",[a._v("the powerful Nushell's piping syntax allows us to create new dataframes by\ntaking data from other dataframes and append it to them. Now, if you list your\ndataframes you will see in total four dataframes")]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" dataframe list\n\n───┬───────┬──────┬─────────┬────────────────────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# │  name │ rows │ columns │        location")]),a._v("\n───┼───────┼──────┼─────────┼────────────────────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$a")]),a._v("    │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),a._v("    │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v("       │ stream\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$a2")]),a._v("   │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),a._v("    │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("4")]),a._v("       │ stream\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$df_a")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("4")]),a._v("    │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("5")]),a._v("       │ "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("test_small.csv\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$df")]),a._v("   │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("10")]),a._v("   │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("8")]),a._v("       │ "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("\\")]),a._v("test_small.csv\n───┴───────┴──────┴─────────┴────────────────────────\n")])])]),t("p",[a._v("One thing that is important to mention is how the memory is being optimized\nwhile working with dataframes, and this is thanks to "),t("strong",[a._v("Apache Arrow")]),a._v(" and\n"),t("strong",[a._v("Polars")]),a._v(". In a very simple representation, each column in a DataFrame is an\nArrow Array, which is using several memory specifications in order to maintain\nthe data as packed as possible (check "),t("a",{attrs:{href:"https://arrow.apache.org/docs/format/Columnar.html",target:"_blank",rel:"noopener noreferrer"}},[a._v("Arrow columnar\nformat"),t("OutboundLink")],1),a._v("). The other\noptimization trick is the fact that whenever possible, the columns from the\ndataframes are shared between dataframes, avoiding memory duplication for the\nsame data. This means that dataframes "),t("code",[a._v("$a")]),a._v(" and "),t("code",[a._v("$a2")]),a._v(" are sharing the same two\ncolumns we created using the "),t("code",[a._v("to-df")]),a._v(" command. For this reason, it isn't\npossible to change the value of a column in a dataframe. However, you can\ncreate new columns based on data from other columns or dataframes.")]),a._v(" "),t("h2",{attrs:{id:"working-with-series"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#working-with-series"}},[a._v("#")]),a._v(" Working with Series")]),a._v(" "),t("p",[a._v("A "),t("code",[a._v("Series")]),a._v(" is the building block of a "),t("code",[a._v("DataFrame")]),a._v(". Each Series represents a\ncolumn with the same data type, and we can create multiple Series of different\ntypes, such as float, int or string.")]),a._v(" "),t("p",[a._v("Let's start our exploration with Series by creating one using the "),t("code",[a._v("to-df")]),a._v("\ncommand:")]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("let")]),a._v(" new "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("9")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("8")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("4")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" dataframe to-df"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$new")]),a._v("\n\n───┬───\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# │ 0")]),a._v("\n───┼───\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("9")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("8")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("4")]),a._v("\n───┴───\n")])])]),t("p",[a._v("We have created a new series from a list of integers (we could have done the\nsame using floats or strings)")]),a._v(" "),t("p",[a._v("Series have their own basic operations defined, and they can be used to create\nother Series. Let's create a new Series by doing some arithmetic on the\npreviously created column.")]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("let")]),a._v(" new_2 "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$new")]),a._v(" * "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),a._v(" + "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("10")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$new_2")]),a._v("\n\n───┬────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# │ 0")]),a._v("\n───┼────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("37")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("34")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("22")]),a._v("\n───┴────\n")])])]),t("p",[a._v("Now we have a new Series that was constructed by doing basic operations on the\nprevious variable.")]),a._v(" "),t("blockquote",[t("p",[a._v("Note: If you want to see how many variables you have stored in memory you can\nuse "),t("code",[a._v("$scope.variables")])])]),a._v(" "),t("p",[a._v("Lets rename our previous Series so it has a memorable name")]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("let")]),a._v(" new_2 "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$new_2")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" dataframe "),t("span",{pre:!0,attrs:{class:"token function"}},[a._v("rename")]),a._v(" memorable"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$new_2")]),a._v("\n\n───┬───────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# │ memorable")]),a._v("\n───┼───────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │        "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("37")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" │        "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("34")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(" │        "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("22")]),a._v("\n───┴───────────\n")])])]),t("p",[a._v("We can also do basic operations with two Series as long as they have the same\ndata type")]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$new")]),a._v(" - "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$new_2")]),a._v("\n\n───┬──────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# │ sub_0_0")]),a._v("\n───┼──────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │     -28\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" │     -26\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(" │     -18\n───┴──────────\n")])])]),t("p",[a._v("And we can add them to previously defined dataframes")]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("let")]),a._v(" new_df "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$a")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" dataframe with-column "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$new")]),a._v(" --name new_col"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$new_df")]),a._v("\n\n───┬───┬───┬─────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# │ b │ a │ new_col")]),a._v("\n───┼───┼───┼─────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" │       "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("9")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("4")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),a._v(" │       "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("8")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("6")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("5")]),a._v(" │       "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("4")]),a._v("\n───┴───┴───┴─────────\n")])])]),t("p",[a._v("The Series stored in a Dataframe can also be used directly, for example,\nwe can multiply columns "),t("code",[a._v("a")]),a._v(" and "),t("code",[a._v("b")]),a._v(" to create a new Series")]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$new_df")]),a._v(".a * "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$new_df")]),a._v(".b\n\n───┬─────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# │ mul_a_b")]),a._v("\n───┼─────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │       "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" │      "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("12")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(" │      "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("30")]),a._v("\n───┴─────────\n")])])]),t("p",[a._v("and we can start piping things in order to create new columns and dataframes")]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("let")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$new_df")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$new_df")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" dataframe with-column "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$new_df")]),a._v(".a * "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$new_df")]),a._v(".b / "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$new_df")]),a._v(".new_col"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v(" --name my_sum"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("let")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$new_df")]),a._v("\n\n───┬───┬───┬─────────┬────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# │ b │ a │ new_col │ my_sum")]),a._v("\n───┼───┼───┼─────────┼────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" │       "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("9")]),a._v(" │      "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("4")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),a._v(" │       "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("8")]),a._v(" │      "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("6")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("5")]),a._v(" │       "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("4")]),a._v(" │      "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("7")]),a._v("\n───┴───┴───┴─────────┴────────\n")])])]),t("p",[a._v("Nushell piping system can help you create very interesting workflows.")]),a._v(" "),t("h2",{attrs:{id:"series-and-masks"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#series-and-masks"}},[a._v("#")]),a._v(" Series and masks")]),a._v(" "),t("p",[a._v("Series have another key use in when working with DataFrames, and it is the fact\nthat we can build boolean masks out of them. Lets start by creating a simple\nmask using the equality operator")]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("let")]),a._v(" mask "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$new")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("==")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("8")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$mask")]),a._v("\n\n───┬─────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# │ new_col")]),a._v("\n───┼─────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("false")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("true")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("false")]),a._v("\n───┴─────────\n")])])]),t("p",[a._v("and with this mask we can now filter a dataframe, like this")]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$new_df")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" dataframe filter-with "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$mask")]),a._v("\n\n───┬───┬───┬─────────┬────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# │ a │ b │ new_col │ my_sum")]),a._v("\n───┼───┼───┼─────────┼────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("4")]),a._v(" │       "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("8")]),a._v(" │      "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v("\n───┴───┴───┴─────────┴────────\n")])])]),t("p",[a._v("Now we have a new dataframe with only the values where the mask was true.")]),a._v(" "),t("p",[a._v("The masks can also be created from Nushell lists as well, for example:")]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("let")]),a._v(" mask1 "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$true")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$true")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$false")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" dataframe to-df mask"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$new_df")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" dataframe filter-with "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$mask1")]),a._v("\n\n───┬───┬───┬─────────┬────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# │ a │ b │ new_col │ my_sum")]),a._v("\n───┼───┼───┼─────────┼────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(" │       "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("9")]),a._v(" │      "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("4")]),a._v(" │       "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("8")]),a._v(" │      "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v("\n───┴───┴───┴─────────┴────────\n")])])]),t("p",[a._v("To create complex masks, we have the "),t("code",[a._v("AND")])]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$mask")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("&&")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$mask1")]),a._v("\n\n───┬──────────────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# │ and_new_col_mask")]),a._v("\n───┼──────────────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("false")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("true")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("false")]),a._v("\n───┴──────────────────\n")])])]),t("p",[a._v("and "),t("code",[a._v("OR")]),a._v(" operations")]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$mask")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("||")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$mask1")]),a._v("\n\n───┬─────────────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# │ or_new_col_mask")]),a._v("\n───┼─────────────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("true")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("true")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("false")]),a._v("\n───┴─────────────────\n")])])]),t("p",[a._v("We can also create a mask by checking if some values exist in other Series.\nUsing the first dataframe that we created we can do something like this")]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("let")]),a._v(" mask3 "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$df")]),a._v(".first "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" dataframe is-in "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("b c"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" dataframe to-df"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("))")]),a._v("\n\n───┬──────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# │ first")]),a._v("\n───┼───────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("false")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("false")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("false")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("true")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("4")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("true")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("5")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("true")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("6")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("true")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("7")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("true")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("8")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("true")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("9")]),a._v(" │ "),t("span",{pre:!0,attrs:{class:"token boolean"}},[a._v("true")]),a._v("\n───┴───────\n")])])]),t("p",[a._v("and this new mask can be used to filter the dataframe")]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$df")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" dataframe filter-with "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$mask3")]),a._v("\n\n───┬───────┬───────┬─────────┬─────────┬───────┬────────┬───────┬─────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# │ int_1 │ int_2 │ float_1 │ float_2 │ first │ second │ third │  word")]),a._v("\n───┼───────┼───────┼─────────┼─────────┼───────┼────────┼───────┼─────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("4")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("14")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.4000")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("3.0000")]),a._v(" │ b     │ a      │ c     │ second\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("15")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.5000")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("4.0000")]),a._v(" │ b     │ a      │ a     │ third\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("6")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("16")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.6000")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("5.0000")]),a._v(" │ b     │ a      │ a     │ second\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("7")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("17")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.7000")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("6.0000")]),a._v(" │ b     │ c      │ a     │ third\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("4")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("8")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("18")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.8000")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("7.0000")]),a._v(" │ c     │ c      │ b     │ eight\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("5")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("9")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("19")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.9000")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("8.0000")]),a._v(" │ c     │ c      │ b     │ ninth\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("6")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("10")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.0000")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("9.0000")]),a._v(" │ c     │ c      │ b     │ ninth\n───┴───────┴───────┴─────────┴─────────┴───────┴────────┴───────┴─────────\n")])])]),t("p",[a._v("Another operation that can be done with masks is setting or replacing a value\nfrom a series. For example, we can change the value in the column "),t("code",[a._v("first")]),a._v(" where\nthe value is equal to "),t("code",[a._v("a")])]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$df")]),a._v(".first "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" dataframe "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("set")]),a._v(" new --mask "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$df")]),a._v(".first "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=~")]),a._v(" a"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n\n───┬────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# │ string")]),a._v("\n───┼────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │ new\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" │ new\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(" │ new\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),a._v(" │ b\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("4")]),a._v(" │ b\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("5")]),a._v(" │ b\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("6")]),a._v(" │ b\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("7")]),a._v(" │ c\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("8")]),a._v(" │ c\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("9")]),a._v(" │ c\n───┴────────\n")])])]),t("h2",{attrs:{id:"series-as-indices"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#series-as-indices"}},[a._v("#")]),a._v(" Series as indices")]),a._v(" "),t("p",[a._v("Series can be also used as a way of filtering a dataframe by using them as a\nlist of indices. For example, let's say that we want to get rows 1, 4, and 6\nfrom our original dataframe. With that in mind, we can use the next command to\nextract that information")]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("let")]),a._v(" indices "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("4")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("6")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" dataframe to-df"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$df")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" dataframe take "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$indices")]),a._v("\n\n───┬───────┬───────┬─────────┬─────────┬───────┬────────┬───────┬────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# │ int_1 │ int_2 │ float_1 │ float_2 │ first │ second │ third │  word")]),a._v("\n───┼───────┼───────┼─────────┼─────────┼───────┼────────┼───────┼────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("12")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.2000")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1.0000")]),a._v(" │ a     │ b      │ c     │ second\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("15")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.5000")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("4.0000")]),a._v(" │ b     │ a      │ a     │ third\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("7")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("17")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.7000")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("6.0000")]),a._v(" │ b     │ c      │ a     │ third\n───┴───────┴───────┴─────────┴─────────┴───────┴────────┴───────┴────────\n")])])]),t("p",[a._v("The command "),t("code",[a._v("take")]),a._v(" is very handy, specially if we mix it with other commands.\nLet's say that we want to extract all rows for the first duplicated element for\ncolumn "),t("code",[a._v("first")]),a._v(". In order to do that, we can use the command "),t("code",[a._v("dataframe arg-unique")]),a._v(" as shown in the next example")]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("let")]),a._v(" indices "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$df")]),a._v(".first "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" dataframe arg-unique"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$df")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" dataframe take "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$indices")]),a._v("\n\n───┬───────┬───────┬─────────┬─────────┬───────┬────────┬───────┬────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# │ int_1 │ int_2 │ float_1 │ float_2 │ first │ second │ third │  word")]),a._v("\n───┼───────┼───────┼─────────┼─────────┼───────┼────────┼───────┼────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("11")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.1000")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1.0000")]),a._v(" │ a     │ b      │ c     │ first\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("4")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("14")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.4000")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("3.0000")]),a._v(" │ b     │ a      │ c     │ second\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("8")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("18")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.8000")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("7.0000")]),a._v(" │ c     │ c      │ b     │ eight\n───┴───────┴───────┴─────────┴─────────┴───────┴────────┴───────┴────────\n")])])]),t("p",[a._v("Or what if we want to create a new sorted dataframe using a column in specific.\nWe can use the "),t("code",[a._v("dataframe arg-sort")]),a._v(" to accomplish that. In the next example we\ncan sort the dataframe by the column "),t("code",[a._v("word")])]),a._v(" "),t("blockquote",[t("p",[a._v("Note. The same result could be accomplished using the command "),t("code",[a._v("sort")])])]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("let")]),a._v(" indices "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$df")]),a._v(".word "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" dataframe arg-sort"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$df")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" dataframe take "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$indices")]),a._v("\n\n───┬───────┬───────┬─────────┬─────────┬───────┬────────┬───────┬────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# │ int_1 │ int_2 │ float_1 │ float_2 │ first │ second │ third │  word")]),a._v("\n───┼───────┼───────┼─────────┼─────────┼───────┼────────┼───────┼────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("8")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("18")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.8000")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("7.0000")]),a._v(" │ c     │ c      │ b     │ eight\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("11")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.1000")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1.0000")]),a._v(" │ a     │ b      │ c     │ first\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("9")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("19")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.9000")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("8.0000")]),a._v(" │ c     │ c      │ b     │ ninth\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("10")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.0000")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("9.0000")]),a._v(" │ c     │ c      │ b     │ ninth\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("4")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("12")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.2000")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1.0000")]),a._v(" │ a     │ b      │ c     │ second\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("5")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("4")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("14")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.4000")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("3.0000")]),a._v(" │ b     │ a      │ c     │ second\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("6")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("6")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("16")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.6000")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("5.0000")]),a._v(" │ b     │ a      │ a     │ second\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("7")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("13")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.3000")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2.0000")]),a._v(" │ a     │ b      │ c     │ third\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("8")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("15")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.5000")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("4.0000")]),a._v(" │ b     │ a      │ a     │ third\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("9")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("7")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("17")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.7000")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("6.0000")]),a._v(" │ b     │ c      │ a     │ third\n───┴───────┴───────┴─────────┴─────────┴───────┴────────┴───────┴────────\n")])])]),t("p",[a._v("And finally, we can create new Series by setting a new value in the marked\nindices. Have a look at the next command")]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("let")]),a._v(" indices "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" dataframe to-df"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(";")]),a._v("\n"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$df")]),a._v(".int_1 "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" dataframe set-with-idx "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("123")]),a._v(" --indices "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$indices")]),a._v("\n\n───┬───────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# │ int_1")]),a._v("\n───┼───────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │   "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("123")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(" │   "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("123")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("4")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("4")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("5")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("6")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("6")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("7")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("7")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("8")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("8")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("9")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("9")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v("\n───┴───────\n")])])]),t("h2",{attrs:{id:"unique-values"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#unique-values"}},[a._v("#")]),a._v(" Unique values")]),a._v(" "),t("p",[a._v("Another operation that can be done with "),t("code",[a._v("Series")]),a._v(" is to search for unique values\nin a list or column. Lets use again the first dataframe we created to test\nthese operations.")]),a._v(" "),t("p",[a._v("The first and most common operation that we have is "),t("code",[a._v("value_counts")]),a._v(". This\ncommand calculates a count of the unique values that exist in a Series. For\nexample, we can use it to count how many occurrences we have in the column\n"),t("code",[a._v("first")])]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$df")]),a._v(".first "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" dataframe value-counts\n\n───┬───────┬────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# │ first │ counts")]),a._v("\n───┼───────┼────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │ b     │      "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("4")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" │ c     │      "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),a._v("\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(" │ a     │      "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),a._v("\n───┴───────┴────────\n")])])]),t("p",[a._v("As expected, the command returns a new dataframe that can be used to do more\nqueries.")]),a._v(" "),t("p",[a._v("Continuing with our exploration of "),t("code",[a._v("Series")]),a._v(", the next thing that we can do is\nto only get the unique unique values from a series, like this")]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$df")]),a._v(".first "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" dataframe unique\n\n───┬───────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# │ first")]),a._v("\n───┼───────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │ c\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" │ b\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(" │ a\n───┴───────\n")])])]),t("p",[a._v("Or we can get a mask that we can use to filter out the rows where data is\nunique or duplicated. For example, we can select the rows for unique values\nin column "),t("code",[a._v("word")])]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$df")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" dataframe filter-with "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$df")]),a._v(".word "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" dataframe is-unique"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n\n───┬───────┬───────┬─────────┬─────────┬───────┬────────┬───────┬───────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# │ int_1 │ int_2 │ float_1 │ float_2 │ first │ second │ third │ word")]),a._v("\n───┼───────┼───────┼─────────┼─────────┼───────┼────────┼───────┼───────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("11")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.1000")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1.0000")]),a._v(" │ a     │ b      │ c     │ first\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("8")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("18")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.8000")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("7.0000")]),a._v(" │ c     │ c      │ b     │ eight\n───┴───────┴───────┴─────────┴─────────┴───────┴────────┴───────┴───────\n")])])]),t("p",[a._v("Or all the duplicated ones")]),a._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$df")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" dataframe filter-with "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token variable"}},[a._v("$df")]),a._v(".word "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" dataframe is-duplicated"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n\n───┬───────┬───────┬─────────┬─────────┬───────┬────────┬───────┬────────\n "),t("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# │ int_1 │ int_2 │ float_1 │ float_2 │ first │ second │ third │  word")]),a._v("\n───┼───────┼───────┼─────────┼─────────┼───────┼────────┼───────┼────────\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("12")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.2000")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1.0000")]),a._v(" │ a     │ b      │ c     │ second\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("13")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.3000")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2.0000")]),a._v(" │ a     │ b      │ c     │ third\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("4")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("14")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.4000")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("3.0000")]),a._v(" │ b     │ a      │ c     │ second\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("15")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.5000")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("4.0000")]),a._v(" │ b     │ a      │ a     │ third\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("4")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("6")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("16")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.6000")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("5.0000")]),a._v(" │ b     │ a      │ a     │ second\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("5")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("7")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("17")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.7000")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("6.0000")]),a._v(" │ b     │ c      │ a     │ third\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("6")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("9")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("19")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.9000")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("8.0000")]),a._v(" │ c     │ c      │ b     │ ninth\n "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("7")]),a._v(" │     "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" │    "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("10")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("0.0000")]),a._v(" │  "),t("span",{pre:!0,attrs:{class:"token number"}},[a._v("9.0000")]),a._v(" │ c     │ c      │ b     │ ninth\n───┴───────┴───────┴─────────┴─────────┴───────┴────────┴───────┴────────\n")])])]),t("h2",{attrs:{id:"dataframes-commands"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#dataframes-commands"}},[a._v("#")]),a._v(" Dataframes commands")]),a._v(" "),t("p",[a._v("So far we have seen quite a few operations that can be done using "),t("code",[a._v("DataFrame")]),a._v("s\ncommands. However, the commands we have used so far, are not all the commands\navailable to work with data and be assured that there will be more as the\nfeature becomes more stable.")]),a._v(" "),t("p",[a._v("The next list show the available dataframe commands with their description, and\nwhenever possible, their analogous nushell command.")]),a._v(" "),t("table",[t("thead",[t("tr",[t("th",[a._v("Command Name")]),a._v(" "),t("th",[a._v("Applies To")]),a._v(" "),t("th",[a._v("Description")]),a._v(" "),t("th",[a._v("Nushell Equivalent")])])]),a._v(" "),t("tbody",[t("tr",[t("td",[a._v("aggregate")]),a._v(" "),t("td",[a._v("DataFrame, GroupBy, Series")]),a._v(" "),t("td",[a._v("Performs an aggregation operation on a dataframe, groupby or series object")]),a._v(" "),t("td",[a._v("math")])]),a._v(" "),t("tr",[t("td",[a._v("all-false")]),a._v(" "),t("td",[a._v("Series")]),a._v(" "),t("td",[a._v("Returns true if all values are false")]),a._v(" "),t("td")]),a._v(" "),t("tr",[t("td",[a._v("all-true")]),a._v(" "),t("td",[a._v("Series")]),a._v(" "),t("td",[a._v("Returns true if all values are true")]),a._v(" "),t("td",[a._v("all?")])]),a._v(" "),t("tr",[t("td",[a._v("arg-max")]),a._v(" "),t("td",[a._v("Series")]),a._v(" "),t("td",[a._v("Return index for max value in series")]),a._v(" "),t("td")]),a._v(" "),t("tr",[t("td",[a._v("arg-min")]),a._v(" "),t("td",[a._v("Series")]),a._v(" "),t("td",[a._v("Return index for min value in series")]),a._v(" "),t("td")]),a._v(" "),t("tr",[t("td",[a._v("arg-sort")]),a._v(" "),t("td",[a._v("Series")]),a._v(" "),t("td",[a._v("Returns indexes for a sorted series")]),a._v(" "),t("td")]),a._v(" "),t("tr",[t("td",[a._v("arg-true")]),a._v(" "),t("td",[a._v("Series")]),a._v(" "),t("td",[a._v("Returns indexes where values are true")]),a._v(" "),t("td")]),a._v(" "),t("tr",[t("td",[a._v("arg-unique")]),a._v(" "),t("td",[a._v("Series")]),a._v(" "),t("td",[a._v("Returns indexes for unique values")]),a._v(" "),t("td")]),a._v(" "),t("tr",[t("td",[a._v("column")]),a._v(" "),t("td",[a._v("DataFrame")]),a._v(" "),t("td",[a._v("Returns the selected column as Series")]),a._v(" "),t("td",[a._v("get")])]),a._v(" "),t("tr",[t("td",[a._v("count-null")]),a._v(" "),t("td",[a._v("Series")]),a._v(" "),t("td",[a._v("Counts null values")]),a._v(" "),t("td")]),a._v(" "),t("tr",[t("td",[a._v("count-unique")]),a._v(" "),t("td",[a._v("Series")]),a._v(" "),t("td",[a._v("Counts unique value")]),a._v(" "),t("td")]),a._v(" "),t("tr",[t("td",[a._v("drop")]),a._v(" "),t("td",[a._v("DataFrame")]),a._v(" "),t("td",[a._v("Creates a new dataframe by dropping the selected columns")]),a._v(" "),t("td",[a._v("drop")])]),a._v(" "),t("tr",[t("td",[a._v("drop-duplicates")]),a._v(" "),t("td",[a._v("DataFrame")]),a._v(" "),t("td",[a._v("Drops duplicate values in dataframe")]),a._v(" "),t("td")]),a._v(" "),t("tr",[t("td",[a._v("drop-nulls")]),a._v(" "),t("td",[a._v("DataFrame, Series")]),a._v(" "),t("td",[a._v("Drops null values in dataframe")]),a._v(" "),t("td")]),a._v(" "),t("tr",[t("td",[a._v("dtypes")]),a._v(" "),t("td",[a._v("DataFrame")]),a._v(" "),t("td",[a._v("Show dataframe data types")]),a._v(" "),t("td")]),a._v(" "),t("tr",[t("td",[a._v("filter-with")]),a._v(" "),t("td",[a._v("DataFrame")]),a._v(" "),t("td",[a._v("Filters dataframe using a mask as reference")]),a._v(" "),t("td")]),a._v(" "),t("tr",[t("td",[a._v("first")]),a._v(" "),t("td",[a._v("DataFrame")]),a._v(" "),t("td",[a._v("Creates new dataframe with first rows")]),a._v(" "),t("td",[a._v("first")])]),a._v(" "),t("tr",[t("td",[a._v("get")]),a._v(" "),t("td",[a._v("DataFrame")]),a._v(" "),t("td",[a._v("Creates dataframe with the selected columns")]),a._v(" "),t("td",[a._v("get")])]),a._v(" "),t("tr",[t("td",[a._v("group-by")]),a._v(" "),t("td",[a._v("DataFrame")]),a._v(" "),t("td",[a._v("Creates a groupby object that can be used for other aggregations")]),a._v(" "),t("td",[a._v("group-by")])]),a._v(" "),t("tr",[t("td",[a._v("is-duplicated")]),a._v(" "),t("td",[a._v("Series")]),a._v(" "),t("td",[a._v("Creates mask indicating duplicated values")]),a._v(" "),t("td")]),a._v(" "),t("tr",[t("td",[a._v("is-in")]),a._v(" "),t("td",[a._v("Series")]),a._v(" "),t("td",[a._v("Checks if elements from a series are contained in right series")]),a._v(" "),t("td",[a._v("in")])]),a._v(" "),t("tr",[t("td",[a._v("is-not-null")]),a._v(" "),t("td",[a._v("Series")]),a._v(" "),t("td",[a._v("Creates mask where value is not null")]),a._v(" "),t("td")]),a._v(" "),t("tr",[t("td",[a._v("is-null")]),a._v(" "),t("td",[a._v("Series")]),a._v(" "),t("td",[a._v("Creates mask where value is null")]),a._v(" "),t("td",[t("code",[a._v("<column_name> == $nothing")])])]),a._v(" "),t("tr",[t("td",[a._v("is-unique")]),a._v(" "),t("td",[a._v("Series")]),a._v(" "),t("td",[a._v("Creates mask indicating unique values")]),a._v(" "),t("td")]),a._v(" "),t("tr",[t("td",[a._v("join")]),a._v(" "),t("td",[a._v("DataFrame")]),a._v(" "),t("td",[a._v("Joins a dataframe using columns as reference")]),a._v(" "),t("td")]),a._v(" "),t("tr",[t("td",[a._v("last")]),a._v(" "),t("td",[a._v("DataFrame")]),a._v(" "),t("td",[a._v("Creates new dataframe with last rows")]),a._v(" "),t("td",[a._v("last")])]),a._v(" "),t("tr",[t("td",[a._v("list")]),a._v(" "),t("td"),a._v(" "),t("td",[a._v("Lists stored dataframes")]),a._v(" "),t("td")]),a._v(" "),t("tr",[t("td",[a._v("melt")]),a._v(" "),t("td",[a._v("DataFrame")]),a._v(" "),t("td",[a._v("Unpivot a DataFrame from wide to long format")]),a._v(" "),t("td")]),a._v(" "),t("tr",[t("td",[a._v("not")]),a._v(" "),t("td",[a._v("Series Inverts boolean mask")]),a._v(" "),t("td"),a._v(" "),t("td")]),a._v(" "),t("tr",[t("td",[a._v("open")]),a._v(" "),t("td"),a._v(" "),t("td",[a._v("Loads dataframe form csv file")]),a._v(" "),t("td",[a._v("open")])]),a._v(" "),t("tr",[t("td",[a._v("pivot")]),a._v(" "),t("td",[a._v("GroupBy")]),a._v(" "),t("td",[a._v("Performs a pivot operation on a groupby object")]),a._v(" "),t("td",[a._v("pivot")])]),a._v(" "),t("tr",[t("td",[a._v("rename")]),a._v(" "),t("td",[a._v("Series")]),a._v(" "),t("td",[a._v("Renames a series")]),a._v(" "),t("td",[a._v("rename")])]),a._v(" "),t("tr",[t("td",[a._v("sample")]),a._v(" "),t("td",[a._v("DataFrame")]),a._v(" "),t("td",[a._v("Create sample dataframe")]),a._v(" "),t("td")]),a._v(" "),t("tr",[t("td",[a._v("select")]),a._v(" "),t("td",[a._v("DataFrame")]),a._v(" "),t("td",[a._v("Creates a new dataframe with the selected columns")]),a._v(" "),t("td",[a._v("select")])]),a._v(" "),t("tr",[t("td",[a._v("set")]),a._v(" "),t("td",[a._v("Series")]),a._v(" "),t("td",[a._v("Sets value where given mask is true")]),a._v(" "),t("td")]),a._v(" "),t("tr",[t("td",[a._v("set-with-idx")]),a._v(" "),t("td",[a._v("Series")]),a._v(" "),t("td",[a._v("Sets value in the given index")]),a._v(" "),t("td")]),a._v(" "),t("tr",[t("td",[a._v("shift")]),a._v(" "),t("td",[a._v("Series")]),a._v(" "),t("td",[a._v("Shifts the values by a given period")]),a._v(" "),t("td")]),a._v(" "),t("tr",[t("td",[a._v("show")]),a._v(" "),t("td",[a._v("DataFrame")]),a._v(" "),t("td",[a._v("Converts a section of the dataframe to a Table or List value")]),a._v(" "),t("td")]),a._v(" "),t("tr",[t("td",[a._v("slice")]),a._v(" "),t("td",[a._v("DataFrame")]),a._v(" "),t("td",[a._v("Creates new dataframe from a slice of rows")]),a._v(" "),t("td")]),a._v(" "),t("tr",[t("td",[a._v("sort")]),a._v(" "),t("td",[a._v("DataFrame, Series")]),a._v(" "),t("td",[a._v("Creates new sorted dataframe or series")]),a._v(" "),t("td",[a._v("sort")])]),a._v(" "),t("tr",[t("td",[a._v("take")]),a._v(" "),t("td",[a._v("DataFrame, Series")]),a._v(" "),t("td",[a._v("Creates new dataframe using the given indices")]),a._v(" "),t("td")]),a._v(" "),t("tr",[t("td",[a._v("to-csv")]),a._v(" "),t("td",[a._v("DataFrame")]),a._v(" "),t("td",[a._v("Saves dataframe to csv file")]),a._v(" "),t("td",[a._v("to csv")])]),a._v(" "),t("tr",[t("td",[a._v("to-df")]),a._v(" "),t("td"),a._v(" "),t("td",[a._v("Converts a pipelined Table or List into Dataframe")]),a._v(" "),t("td")]),a._v(" "),t("tr",[t("td",[a._v("to-dummies")]),a._v(" "),t("td",[a._v("DataFrame")]),a._v(" "),t("td",[a._v("Creates a new dataframe with dummy variables")]),a._v(" "),t("td")]),a._v(" "),t("tr",[t("td",[a._v("to-parquet")]),a._v(" "),t("td",[a._v("DataFrame")]),a._v(" "),t("td",[a._v("Saves dataframe to parquet file")]),a._v(" "),t("td")]),a._v(" "),t("tr",[t("td",[a._v("unique")]),a._v(" "),t("td",[a._v("Series")]),a._v(" "),t("td",[a._v("Returns unique values from a series")]),a._v(" "),t("td",[a._v("uniq")])]),a._v(" "),t("tr",[t("td",[a._v("value-counts")]),a._v(" "),t("td",[a._v("Series")]),a._v(" "),t("td",[a._v("Returns a dataframe with the counts for unique values in series")]),a._v(" "),t("td")]),a._v(" "),t("tr",[t("td",[a._v("where")]),a._v(" "),t("td",[a._v("DataFrame")]),a._v(" "),t("td",[a._v("Filter dataframe to match the condition")]),a._v(" "),t("td",[a._v("where")])]),a._v(" "),t("tr",[t("td",[a._v("with-column")]),a._v(" "),t("td",[a._v("DataFrame")]),a._v(" "),t("td",[a._v("Adds a series to the dataframe")]),a._v(" "),t("td",[t("code",[a._v("insert <column_name> <value> | update <column_name> { <new_value> }")])])])])]),a._v(" "),t("h2",{attrs:{id:"future-of-dataframes"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#future-of-dataframes"}},[a._v("#")]),a._v(" Future of Dataframes")]),a._v(" "),t("p",[a._v("We hope that by the end of this page you have a solid grasp of how to use the\ndataframe commands. As you can see they offer powerful operations that can\nhelp you process data faster and natively.")]),a._v(" "),t("p",[a._v('However, the future of these dataframes is still very experimental. New\ncommands and tools that take advantage of these commands will be added as they\nmature. For example, the next step for dataframes is the introduction of Lazy\nDataframes. These will allow you to define complex data operations that will be\nexecuted until you decide to "finish" the pipe. This will give nushell the\nchance to select the optimal plan to query the data you would be asking for.')]),a._v(" "),t("p",[a._v("Keep visiting this book in order to check the new things happening to\ndataframes and how they can help you process data faster and efficiently.")])])}),[],!1,null,null,null);s.default=n.exports}}]);